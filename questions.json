[
  {
    "id": 1,
    "type": "기출문제",
    "round": "2021년 2회",
    "section": "",
    "question_number": 1,
    "question": "표본 크기가 25이고, 표본평균이 90일 때 95% 신뢰구간을 구하시오. 단, 모표준편차는 알려져 있지 않고 표본표준편차가 주어졌을 때 사용하는 분포는?",
    "options": [
      "Z분포 (정규분포)",
      "t분포",
      "F분포",
      "카이제곱분포"
    ],
    "correct": 1,
    "explanation": "모표준편차를 모르고 표본표준편차를 사용할 때는 t분포를 사용합니다. 특히 표본 크기가 30 미만일 때 t분포가 적절합니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 2,
    "type": "기출문제",
    "round": "2021년 2회",
    "section": "딥러닝",
    "question_number": 2,
    "question": "CNN에서 5×5 입력에 3×3 필터를 Stride 1로 적용할 때, 출력 Feature Map의 크기는?",
    "options": [
      "1×1",
      "2×2",
      "3×3",
      "4×4"
    ],
    "correct": 2,
    "explanation": "Feature Map 크기 = (입력크기 - 필터크기) / Stride + 1 = (5-3)/1 + 1 = 3이므로 3×3입니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 3,
    "type": "기출문제",
    "round": "2021년 2회",
    "section": "",
    "question_number": 3,
    "question": "ROC 곡선에서 TPR이 9/10이고 FPR이 1/4일 때, 이 모델의 성능은?",
    "options": [
      "매우 좋음 (TPR 높고 FPR 낮음)",
      "좋지 않음 (TPR 낮고 FPR 높음)",
      "보통 (TPR과 FPR 모두 중간)",
      "판단하기 어려움"
    ],
    "correct": 0,
    "explanation": "TPR(True Positive Rate)이 0.9로 높고 FPR(False Positive Rate)이 0.25로 상대적으로 낮으므로 좋은 성능의 모델입니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 4,
    "type": "기출문제",
    "round": "2021년 3회",
    "section": "시계열분석",
    "question_number": 4,
    "question": "ARIMA(p,d,q) 모델에서 'd' 파라미터의 의미는?",
    "options": [
      "자기회귀(AR) 차수",
      "차분(Differencing) 횟수",
      "이동평균(MA) 차수",
      "계절성 주기"
    ],
    "correct": 1,
    "explanation": "ARIMA(p,d,q) 모델에서 d는 시계열을 정상화하기 위한 차분(differencing) 횟수를 의미합니다. p는 AR 차수, q는 MA 차수입니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 5,
    "type": "기출문제",
    "round": "2021년 3회",
    "section": "",
    "question_number": 5,
    "question": "정밀도(Precision)와 재현율(Recall)이 모두 높은 모델의 특징은?",
    "options": [
      "False Positive와 False Negative가 모두 높다",
      "False Positive와 False Negative가 모두 낮다",
      "True Positive만 높다",
      "True Negative만 높다"
    ],
    "correct": 1,
    "explanation": "정밀도가 높으려면 False Positive가 낮아야 하고, 재현율이 높으려면 False Negative가 낮아야 합니다. 따라서 둘 다 높으려면 FP와 FN이 모두 낮아야 합니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 6,
    "type": "기출문제",
    "round": "2021년 3회",
    "section": "",
    "question_number": 6,
    "question": "과적합(Overfitting)을 방지하는 방법이 아닌 것은?",
    "options": [
      "교차검증(Cross Validation) 사용",
      "정규화(Regularization) 적용",
      "훈련 데이터 증가",
      "모델 복잡도 증가"
    ],
    "correct": 3,
    "explanation": "모델 복잡도를 증가시키면 과적합이 더 심해집니다. 과적합 방지를 위해서는 모델 복잡도를 줄이거나, 정규화, 교차검증, 조기 종료 등의 기법을 사용합니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 7,
    "type": "기출문제",
    "round": "2021년 3회",
    "section": "",
    "question_number": 7,
    "question": "다음 중 감산 혼합(Subtractive Color) 모델은?",
    "options": [
      "RGB",
      "HSV",
      "CMYK",
      "LAB"
    ],
    "correct": 2,
    "explanation": "CMYK(Cyan, Magenta, Yellow, Black)는 인쇄에 사용되는 감산 혼합 색상 모델입니다. RGB는 빛의 삼원색을 이용한 가산 혼합 모델입니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 8,
    "type": "기출문제",
    "round": "2021년 3회",
    "section": "데이터 시각화",
    "question_number": 8,
    "question": "세 개의 연속형 변수를 동시에 시각화하기에 적합한 차트는?",
    "options": [
      "Scatter Plot",
      "Pie Chart",
      "Bubble Chart",
      "Bar Chart"
    ],
    "correct": 2,
    "explanation": "Bubble Chart는 x축, y축에 두 변수를 놓고 버블의 크기로 세 번째 변수를 표현하여 세 개의 연속형 변수를 동시에 시각화할 수 있습니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 9,
    "type": "기출문제",
    "round": "2022년 4회",
    "section": "",
    "question_number": 9,
    "question": "데이터 품질의 측정 요소가 아닌 것은?",
    "options": [
      "정확성(Accuracy)",
      "적시성(Timeliness)",
      "완전성(Completeness)",
      "불완전성(Incompleteness)"
    ],
    "correct": 3,
    "explanation": "데이터 품질의 주요 측정 요소는 정확성, 적시성, 완전성, 일관성(Consistency) 등입니다. 불완전성은 품질 측정 요소가 아니라 완전성의 반대 개념입니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 10,
    "type": "기출문제",
    "round": "2022년 4회",
    "section": "",
    "question_number": 10,
    "question": "모집단이 N(50,2²)을 따르고 표본크기가 16일 때, 표본평균의 분포는?",
    "options": [
      "N(50, 2²/16)",
      "N(50, 2²)",
      "N(50, 2/√16)",
      "N(50, 2)"
    ],
    "correct": 0,
    "explanation": "표본평균의 분포는 N(모평균, 모분산/표본크기)를 따르므로 N(50, 2²/16) = N(50, 4/16) = N(50, 0.25)입니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 11,
    "type": "기출문제",
    "round": "2022년 4회",
    "section": "",
    "question_number": 11,
    "question": "Min-Max 정규화에 대한 설명으로 옳은 것은?",
    "options": [
      "데이터를 0과 1 사이의 값으로 변환한다",
      "데이터를 평균 0, 표준편차 1로 변환한다",
      "데이터의 분포를 정규분포로 변환한다",
      "데이터의 이상치를 제거한다"
    ],
    "correct": 0,
    "explanation": "Min-Max 정규화는 데이터를 최솟값과 최댓값을 이용하여 0과 1 사이의 값으로 변환하는 기법입니다. 공식: (x - min) / (max - min)",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 12,
    "type": "기출문제",
    "round": "2022년 4회",
    "section": "",
    "question_number": 12,
    "question": "다음 중 선형분리가 불가능한 논리 게이트는?",
    "options": [
      "AND",
      "OR",
      "NOR",
      "XOR"
    ],
    "correct": 3,
    "explanation": "XOR 게이트는 선형분리가 불가능한 대표적인 문제입니다. 단층 퍼셉트론으로는 해결할 수 없고 다층 퍼셉트론이 필요합니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 13,
    "type": "기출문제",
    "round": "2022년 4회",
    "section": "",
    "question_number": 13,
    "question": "연관규칙 학습에서 사용되는 대표적인 알고리즘은?",
    "options": [
      "K-means",
      "Apriori",
      "SVM",
      "Decision Tree"
    ],
    "correct": 1,
    "explanation": "Apriori 알고리즘은 장바구니 분석 등에서 연관규칙을 찾는 대표적인 알고리즘입니다. 최소 지지도를 만족하는 빈발 아이템셋을 찾아 연관규칙을 생성합니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 14,
    "type": "기출문제",
    "round": "2022년 5회",
    "section": "",
    "question_number": 14,
    "question": "다음 중 분산 데이터베이스 관리 시스템(DBMS)의 특징이 아닌 것은?",
    "options": [
      "데이터의 분산 저장",
      "투명성(Transparency) 제공",
      "단일 장애점(Single Point of Failure) 존재",
      "확장성(Scalability) 향상"
    ],
    "correct": 2,
    "explanation": "분산 DBMS는 단일 장애점을 제거하여 시스템의 가용성을 높이는 것이 주요 목적 중 하나입니다. 단일 장애점 존재는 분산 시스템의 특징이 아닙니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 15,
    "type": "기출문제",
    "round": "2022년 5회",
    "section": "",
    "question_number": 15,
    "question": "FTP(File Transfer Protocol)에 대한 설명으로 옳은 것은?",
    "options": [
      "HTTP보다 보안이 뛰어나다",
      "파일 전송 전용 프로토콜이다",
      "웹 페이지 전송에 주로 사용된다",
      "실시간 통신에 최적화되어 있다"
    ],
    "correct": 1,
    "explanation": "FTP는 File Transfer Protocol의 줄임말로 파일 전송을 위한 전용 프로토콜입니다. 텍스트와 바이너리 파일을 네트워크를 통해 전송하는 데 사용됩니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 16,
    "type": "기출문제",
    "round": "2022년 5회",
    "section": "",
    "question_number": 16,
    "question": "두 변수 X, Y의 공분산이 Cov(X,Y) < 0일 때, 이는 무엇을 의미하는가?",
    "options": [
      "X가 증가하면 Y도 증가한다",
      "X가 증가하면 Y는 감소한다",
      "X와 Y는 독립이다",
      "X와 Y의 관계를 알 수 없다"
    ],
    "correct": 1,
    "explanation": "공분산이 음수일 때는 두 변수가 음의 상관관계를 가진다는 의미입니다. 즉, 한 변수가 증가하면 다른 변수는 감소하는 경향을 보입니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 17,
    "type": "기출문제",
    "round": "2022년 5회",
    "section": "",
    "question_number": 17,
    "question": "머신러닝에서 target variable과 가장 관련이 적은 특성(feature)을 제거하는 기법은?",
    "options": [
      "Principal Component Analysis",
      "Feature Selection",
      "Data Normalization",
      "Cross Validation"
    ],
    "correct": 1,
    "explanation": "Feature Selection은 모델 성능 향상을 위해 관련성이 낮은 특성을 제거하고 중요한 특성만을 선택하는 기법입니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 18,
    "type": "기출문제",
    "round": "2022년 5회",
    "section": "통계",
    "question_number": 18,
    "question": "ANOVA(분산분석)에서 귀무가설은?",
    "options": [
      "모든 그룹의 평균이 다르다",
      "모든 그룹의 평균이 같다",
      "그룹 간 분산이 다르다",
      "그룹 내 분산이 같다"
    ],
    "correct": 1,
    "explanation": "ANOVA의 귀무가설(H0)은 '모든 그룹의 모평균이 같다'입니다. 이를 기각하면 적어도 하나의 그룹 평균이 다르다고 결론내립니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 19,
    "type": "기출문제",
    "round": "2023년 6회",
    "section": "",
    "question_number": 19,
    "question": "실시간 데이터 수집에 가장 적합한 방법은?",
    "options": [
      "FTP를 통한 배치 전송",
      "API를 통한 실시간 전송",
      "DVD 매체를 통한 물리적 전송",
      "이메일을 통한 수동 전송"
    ],
    "correct": 1,
    "explanation": "API(Application Programming Interface)를 통한 실시간 전송이 실시간 데이터 수집에 가장 적합합니다. FTP는 주로 배치 처리에 사용됩니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 20,
    "type": "기출문제",
    "round": "2023년 6회",
    "section": "",
    "question_number": 20,
    "question": "데이터 분석 프로세스에서 모델링 이전 단계는?",
    "options": [
      "Post-processing",
      "Pre-processing",
      "Model validation",
      "Result interpretation"
    ],
    "correct": 1,
    "explanation": "Pre-processing(전처리)는 원시 데이터를 분석에 적합한 형태로 변환하는 모델링 이전 단계입니다. 데이터 정제, 변환, 통합 등의 작업을 포함합니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 21,
    "type": "기출문제",
    "round": "2023년 6회",
    "section": "",
    "question_number": 21,
    "question": "빅데이터 3V 중 데이터의 생성 및 처리 속도를 나타내는 것은?",
    "options": [
      "Volume(크기)",
      "Velocity(속도)",
      "Variety(다양성)",
      "Veracity(정확성)"
    ],
    "correct": 1,
    "explanation": "Velocity(속도)는 데이터가 생성되고 처리되는 속도를 나타내는 빅데이터의 특성입니다. 실시간 스트리밍 데이터의 중요성이 증가하면서 주목받는 특성입니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 22,
    "type": "기출문제",
    "round": "2023년 6회",
    "section": "",
    "question_number": 22,
    "question": "데이터 거버넌스의 핵심 구성 요소가 아닌 것은?",
    "options": [
      "데이터 품질 관리",
      "데이터 보안 정책",
      "데이터 아키텍처",
      "시스템 하드웨어 사양"
    ],
    "correct": 3,
    "explanation": "데이터 거버넌스는 데이터 품질, 보안, 아키텍처, 생명주기 관리 등을 포함합니다. 시스템 하드웨어 사양은 IT 인프라 영역으로 데이터 거버넌스의 직접적인 구성 요소가 아닙니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 23,
    "type": "기출문제",
    "round": "2023년 7회",
    "section": "",
    "question_number": 23,
    "question": "SVD(Singular Value Decomposition)에 대한 설명으로 옳은 것은?",
    "options": [
      "정방행렬에만 적용 가능하다",
      "임의의 m×n 행렬에 적용 가능하다",
      "대칭행렬에만 적용 가능하다",
      "양의 정부호 행렬에만 적용 가능하다"
    ],
    "correct": 1,
    "explanation": "SVD는 임의의 m×n 실행렬에 적용 가능한 행렬 분해 기법입니다. 차원 축소, 추천 시스템, 이미지 압축 등에 활용됩니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 24,
    "type": "기출문제",
    "round": "2023년 7회",
    "section": "데이터 시각화",
    "question_number": 24,
    "question": "Box plot에서 이상치(outlier) 판별 기준은?",
    "options": [
      "Q1 - 1.5×IQR 미만 또는 Q3 + 1.5×IQR 초과",
      "평균 ± 2×표준편차 범위 밖",
      "최솟값과 최댓값의 5% 범위 밖",
      "중위수 ± 1.5×표준편차 범위 밖"
    ],
    "correct": 0,
    "explanation": "Box plot에서 이상치는 Q1 - 1.5×IQR보다 작거나 Q3 + 1.5×IQR보다 큰 값으로 정의됩니다. 여기서 IQR = Q3 - Q1입니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 25,
    "type": "기출문제",
    "round": "2023년 7회",
    "section": "데이터 시각화",
    "question_number": 25,
    "question": "Q-Q plot의 주요 용도는?",
    "options": [
      "두 변수 간의 상관관계 확인",
      "데이터의 정규성 검정",
      "시계열 데이터의 추세 분석",
      "범주형 데이터의 분포 확인"
    ],
    "correct": 1,
    "explanation": "Q-Q plot(Quantile-Quantile plot)은 표본 분위수와 이론적 분위수를 비교하여 데이터가 특정 분포(주로 정규분포)를 따르는지 시각적으로 확인하는 도구입니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 26,
    "type": "기출문제",
    "round": "2023년 7회",
    "section": "",
    "question_number": 26,
    "question": "L1 정규화(L1 regularization)의 특징은?",
    "options": [
      "특성 선택(feature selection) 효과가 있다",
      "모든 가중치를 동등하게 감소시킨다",
      "이차 함수 형태의 패널티를 적용한다",
      "오버피팅을 전혀 방지하지 못한다"
    ],
    "correct": 0,
    "explanation": "L1 정규화는 일부 가중치를 0으로 만들어 자동으로 특성 선택 효과를 제공합니다. 이는 Lasso 회귀의 핵심 특징입니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 27,
    "type": "기출문제",
    "round": "2023년 7회",
    "section": "딥러닝",
    "question_number": 27,
    "question": "신경망에서 은닉층 뉴런의 출력값이 f(x) = 0일 때, 다음 중 가능한 활성화 함수는?",
    "options": [
      "Sigmoid (출력 범위 0~1)",
      "ReLU (출력 범위 0~∞)",
      "Tanh (출력 범위 -1~1)",
      "모두 가능하다"
    ],
    "correct": 3,
    "explanation": "모든 활성화 함수는 특정 입력 조건에서 0을 출력할 수 있습니다. ReLU는 입력이 0 이하일 때, Sigmoid는 입력이 매우 작을 때, Tanh는 입력이 0일 때 0을 출력합니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 28,
    "type": "기출문제",
    "round": "2024년 8회",
    "section": "",
    "question_number": 28,
    "question": "VIF(Variance Inflation Factor)에 대한 설명으로 옳은 것은?",
    "options": [
      "다중공선성(multicollinearity)을 측정하는 지표이다",
      "모델의 예측 정확도를 측정하는 지표이다",
      "데이터의 분산을 측정하는 지표이다",
      "특성 간 상관관계를 측정하는 지표이다"
    ],
    "correct": 0,
    "explanation": "VIF는 회귀분석에서 독립변수들 간의 다중공선성 정도를 측정하는 지표입니다. 일반적으로 VIF > 10이면 다중공선성이 심각하다고 판단합니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 29,
    "type": "기출문제",
    "round": "2024년 8회",
    "section": "",
    "question_number": 29,
    "question": "다음 중 확률적 샘플링 기법이 아닌 것은?",
    "options": [
      "단순무작위샘플링(Simple Random Sampling)",
      "층화샘플링(Stratified Sampling)",
      "편의샘플링(Convenience Sampling)",
      "군집샘플링(Cluster Sampling)"
    ],
    "correct": 2,
    "explanation": "편의샘플링은 연구자의 편의에 따라 표본을 선택하는 비확률적 샘플링 기법입니다. 나머지는 모두 확률적 샘플링 기법입니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 30,
    "type": "기출문제",
    "round": "2024년 8회",
    "section": "",
    "question_number": 30,
    "question": "앙상블 학습 기법 중 여러 모델의 예측을 다수결로 결정하는 방법은?",
    "options": [
      "Bagging",
      "Boosting",
      "Voting",
      "Stacking"
    ],
    "correct": 2,
    "explanation": "Voting(투표)은 여러 모델의 예측 결과를 다수결 원칙에 따라 최종 예측을 결정하는 앙상블 기법입니다. Hard voting과 Soft voting으로 구분됩니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 31,
    "type": "기출문제",
    "round": "2024년 8회",
    "section": "",
    "question_number": 31,
    "question": "상대위험도(RR, Relative Risk)가 1보다 클 때의 해석은?",
    "options": [
      "노출군에서 질병 발생 위험이 더 낮다",
      "노출군에서 질병 발생 위험이 더 높다",
      "노출군과 비노출군의 위험이 같다",
      "상관관계가 없다"
    ],
    "correct": 1,
    "explanation": "상대위험도(RR) > 1이면 노출군에서 질병 발생 위험이 비노출군보다 높다는 의미입니다. RR = 1이면 위험이 같고, RR < 1이면 노출군의 위험이 더 낮습니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 32,
    "type": "기출문제",
    "round": "2024년 8회",
    "section": "회귀분석",
    "question_number": 32,
    "question": "Ridge 회귀에서 사용하는 정규화 항은?",
    "options": [
      "L1 penalty (절댓값의 합)",
      "L2 penalty (제곱합)",
      "L1과 L2의 조합",
      "로그 함수"
    ],
    "correct": 1,
    "explanation": "Ridge 회귀는 L2 penalty(제곱합)를 사용하는 정규화 기법입니다. L1 penalty는 Lasso, L1+L2 조합은 Elastic Net에서 사용됩니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 33,
    "type": "기출문제",
    "round": "2024년 8회",
    "section": "",
    "question_number": 33,
    "question": "최대우도추정(MLE)과 최소제곱법(LSE)의 관계에 대한 설명으로 옳은 것은?",
    "options": [
      "항상 동일한 결과를 제공한다",
      "정규분포 가정 하에서 동일한 결과를 제공한다",
      "전혀 관련이 없다",
      "MLE가 항상 LSE보다 우수하다"
    ],
    "correct": 1,
    "explanation": "오차가 정규분포를 따른다는 가정 하에서 최대우도추정과 최소제곱법은 동일한 결과를 제공합니다. 이는 통계학의 중요한 이론적 결과 중 하나입니다.",
    "difficulty": "기출문제",
    "difficulty_level": 3
  },
  {
    "id": 34,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 1,
    "question": "빅데이터의 5V 중 '신뢰성'을 의미하는 것은?",
    "options": [
      "Volume",
      "Velocity",
      "Variety",
      "Veracity"
    ],
    "correct": 3,
    "explanation": "빅데이터의 5V는 Volume(규모), Velocity(속도), Variety(다양성), Value(가치), Veracity(신뢰성)입니다. Veracity는 데이터의 정확성과 신뢰성을 의미합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 35,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 2,
    "question": "DIKW 피라미드에서 가장 상위 단계는?",
    "options": [
      "Data",
      "Information",
      "Knowledge",
      "Wisdom"
    ],
    "correct": 3,
    "explanation": "DIKW 피라미드는 Data → Information → Knowledge → Wisdom 순으로 구성되며, Wisdom(지혜)이 가장 상위 단계입니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 36,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 3,
    "question": "SECI 모델에서 형식지를 암묵지로 변환하는 과정은?",
    "options": [
      "공통화(Socialization)",
      "표출화(Externalization)",
      "연결화(Combination)",
      "내면화(Internalization)"
    ],
    "correct": 3,
    "explanation": "SECI 모델에서 내면화(Internalization)는 형식지를 암묵지로 변환하는 과정입니다. 공통화는 암묵지→암묵지, 표출화는 암묵지→형식지, 연결화는 형식지→형식지입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 37,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 4,
    "question": "NoSQL DBMS의 특징으로 옳지 않은 것은?",
    "options": [
      "비정형 데이터 저장 및 관리에 적합하다",
      "형식에 얽매이지 않는다",
      "테이블 형태로 데이터를 정리한다",
      "인스타그램, 유튜브 등에서 사용한다"
    ],
    "correct": 2,
    "explanation": "NoSQL DBMS는 비정형 데이터 저장에 적합하고 형식에 얽매이지 않는 특징이 있습니다. 테이블 형태로 데이터를 정리하는 것은 관계형 DBMS(RDBMS)의 특징입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 38,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 5,
    "question": "데이터베이스의 특징을 나타내는 '공통 저변'에서 '저'가 의미하는 것은?",
    "options": [
      "공용 데이터",
      "통합된 데이터",
      "저장된 데이터",
      "변화되는 데이터"
    ],
    "correct": 2,
    "explanation": "데이터베이스의 특징 '공통 저변'은 공용 데이터, 통합된 데이터, 저장된 데이터, 변화되는 데이터를 의미합니다. '저'는 저장된 데이터를 나타냅니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 39,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 6,
    "question": "빅데이터 활용을 위한 3대 요소는?",
    "options": [
      "인력, 자원, 기술",
      "수집, 저장, 분석",
      "정형, 반정형, 비정형",
      "Volume, Velocity, Variety"
    ],
    "correct": 0,
    "explanation": "빅데이터 활용을 위한 3대 요소는 인력(분석 전문가), 자원(데이터 및 하드웨어), 기술(분석 기술 및 도구)입니다. 암기 팁으로 '인자기'를 사용할 수 있습니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 40,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 7,
    "question": "OLTP에 대한 설명으로 옳은 것은?",
    "options": [
      "대화식 분석 처리",
      "거래 단위 트랜잭션 처리",
      "고객 관계 관리",
      "공급망 관리"
    ],
    "correct": 1,
    "explanation": "OLTP(Online Transaction Processing)는 거래 단위 트랜잭션 처리를 의미합니다. OLAP는 대화식 분석 처리, CRM은 고객 관계 관리, SCM은 공급망 관리입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 41,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 8,
    "question": "메타데이터(Metadata)에 대한 설명으로 옳은 것은?",
    "options": [
      "데이터를 설명하기 위한 데이터",
      "데이터의 타입과 값을 정의",
      "DB에 대한 전반적인 명세",
      "정렬 탐색을 위한 데이터의 이름"
    ],
    "correct": 0,
    "explanation": "메타데이터(Metadata)는 데이터를 설명하기 위한 데이터입니다. 인스턴스는 데이터 타입과 값을 정의, 스키마는 DB에 대한 전반적인 명세, 인덱스는 정렬 탐색을 위한 데이터의 이름입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 42,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 9,
    "question": "개인정보 비식별화 기법이 아닌 것은?",
    "options": [
      "가명 처리",
      "총계 처리",
      "데이터 마스킹",
      "데이터 암호화"
    ],
    "correct": 3,
    "explanation": "개인정보 비식별화 기법에는 가명처리, 총계처리, 데이터 마스킹, 특이화(일반화), 범주화 등이 있습니다. 데이터 암호화는 개인정보 보호 기법이지만 비식별화 기법은 아닙니다.",
    "difficulty": "★★★★★",
    "difficulty_level": 5
  },
  {
    "id": 43,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 10,
    "question": "MyData의 3대 원칙은?",
    "options": [
      "수집, 저장, 활용",
      "개인 주도, 시장 주도, 정부 지원",
      "정형, 반정형, 비정형",
      "수집, 전송, 활용"
    ],
    "correct": 1,
    "explanation": "MyData의 3대 원칙은 개인 주도(개인이 본인 데이터 활용 직접 결정), 시장 주도(민간이 주도하는 데이터 경제), 정부 지원(제도·기술적 기반 마련)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 44,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 11,
    "question": "하둡(Hadoop) HDFS의 특징으로 옳지 않은 것은?",
    "options": [
      "분산 저장이 가능하다",
      "높은 내결함성을 제공한다",
      "단일 장애점이 존재한다",
      "대용량 데이터 처리에 최적화되어 있다"
    ],
    "correct": 2,
    "explanation": "하둡 HDFS는 분산 저장, 높은 내결함성, 대용량 데이터 처리에 최적화된 특징이 있습니다. 단일 장애점(Single Point of Failure)을 해결하는 것이 HDFS의 주요 목적 중 하나입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 45,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 12,
    "question": "데이터 웨어하우스(Data Warehouse)의 특징이 아닌 것은?",
    "options": [
      "주제 지향적(Subject-Oriented)",
      "통합적(Integrated)",
      "시간 변동적(Time-Variant)",
      "실시간 처리(Real-time Processing)"
    ],
    "correct": 3,
    "explanation": "데이터 웨어하우스의 특징은 주제 지향적, 통합적, 시간 변동적, 비휘발적(Non-Volatile)입니다. 실시간 처리보다는 배치 처리에 최적화되어 있습니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 46,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 13,
    "question": "ETL 프로세스에서 'T'가 의미하는 것은?",
    "options": [
      "Transfer",
      "Transform",
      "Transmit",
      "Transpose"
    ],
    "correct": 1,
    "explanation": "ETL은 Extraction(추출), Transformation(변환), Loading(적재)의 약자입니다. 'T'는 Transform(변환)을 의미합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 47,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 14,
    "question": "CRISP-DM 방법론의 6단계 중 첫 번째 단계는?",
    "options": [
      "데이터 이해",
      "비즈니스 이해",
      "데이터 준비",
      "모델링"
    ],
    "correct": 1,
    "explanation": "CRISP-DM 방법론의 6단계는 ①비즈니스 이해 ②데이터 이해 ③데이터 준비 ④모델링 ⑤평가 ⑥배포 순서입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 48,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 15,
    "question": "KDD(Knowledge Discovery in Databases) 프로세스에서 첫 번째 단계는?",
    "options": [
      "Selection",
      "Preprocessing",
      "Transformation",
      "Data Mining"
    ],
    "correct": 0,
    "explanation": "KDD 프로세스는 ①선택(Selection) ②전처리(Preprocessing) ③변환(Transformation) ④데이터마이닝(Data Mining) ⑤해석/평가(Interpretation/Evaluation) 순서입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 49,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 16,
    "question": "빅데이터 분석 프로젝트에서 Problem Discovery 단계에 해당하지 않는 것은?",
    "options": [
      "What (무엇을)",
      "Why (왜)",
      "How (어떻게)",
      "When (언제)"
    ],
    "correct": 2,
    "explanation": "Problem Discovery 단계에서는 What(무엇을), Why(왜), When(언제)를 중점적으로 다룹니다. How(어떻게)는 Solution Search 단계에서 다루어집니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 50,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 17,
    "question": "STEEP 분석에서 'E'가 두 번 나오는데, 이 두 'E'가 의미하는 것은?",
    "options": [
      "Economic, Environmental",
      "Educational, Ethical",
      "Electronic, Emotional",
      "Efficient, Effective"
    ],
    "correct": 0,
    "explanation": "STEEP 분석은 Social(사회적), Technological(기술적), Economic(경제적), Environmental(환경적), Political(정치적) 요인을 분석하는 기법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 51,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 18,
    "question": "데이터 품질 검증 항목이 아닌 것은?",
    "options": [
      "완전성(Completeness)",
      "정확성(Accuracy)",
      "일관성(Consistency)",
      "확장성(Scalability)"
    ],
    "correct": 3,
    "explanation": "데이터 품질 검증 항목에는 완전성, 정확성, 일관성, 유효성, 유일성 등이 있습니다. 확장성은 시스템 성능과 관련된 항목입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 52,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 개론",
    "question_number": 19,
    "question": "스키마 온 라이트(Schema on Write)와 스키마 온 리드(Schema on Read)에 대한 설명으로 옳은 것은?",
    "options": [
      "둘 다 동일한 개념이다",
      "스키마 온 라이트는 NoSQL에서 주로 사용된다",
      "스키마 온 리드는 RDBMS에서 주로 사용된다",
      "스키마 온 리드는 데이터를 읽을 때 스키마를 정의한다"
    ],
    "correct": 3,
    "explanation": "스키마 온 라이트는 데이터를 저장할 때 스키마를 정의하는 방식(RDBMS)이고, 스키마 온 리드는 데이터를 읽을 때 스키마를 정의하는 방식(NoSQL, 빅데이터)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 53,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 20,
    "question": "결측값 처리 방법 중 MCAR은 무엇의 약자인가?",
    "options": [
      "Missing Completely At Random",
      "Missing Conditionally At Random",
      "Missing Constantly At Random",
      "Missing Correctly At Random"
    ],
    "correct": 0,
    "explanation": "MCAR은 Missing Completely At Random의 약자로, 결측값이 완전히 무작위로 발생한 경우를 의미합니다. MAR(Missing At Random), MNAR(Missing Not At Random)과 구별됩니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 54,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 21,
    "question": "이상값 탐지 방법 중 IQR을 이용한 방법에서 이상값의 기준은?",
    "options": [
      "Q1 - 1.0×IQR 미만, Q3 + 1.0×IQR 초과",
      "Q1 - 1.5×IQR 미만, Q3 + 1.5×IQR 초과",
      "Q1 - 2.0×IQR 미만, Q3 + 2.0×IQR 초과",
      "Q1 - 3.0×IQR 미만, Q3 + 3.0×IQR 초과"
    ],
    "correct": 1,
    "explanation": "IQR(Inter Quartile Range) 방법에서는 Q1 - 1.5×IQR 미만이거나 Q3 + 1.5×IQR 초과하는 값을 이상값으로 판단합니다. IQR = Q3 - Q1입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 55,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 22,
    "question": "Z-score 정규화 공식에서 분모에 해당하는 것은?",
    "options": [
      "평균",
      "최댓값",
      "표준편차",
      "중앙값"
    ],
    "correct": 2,
    "explanation": "Z-score 정규화는 Z = (X - μ)/σ 공식을 사용합니다. 여기서 μ는 평균, σ는 표준편차입니다. 표준편차가 분모에 해당합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 56,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 23,
    "question": "Min-Max 정규화의 결과 범위는?",
    "options": [
      "[-1, 1]",
      "[0, 1]",
      "[-∞, ∞]",
      "[0, 100]"
    ],
    "correct": 1,
    "explanation": "Min-Max 정규화는 데이터를 0과 1 사이의 값으로 변환하는 방법입니다. 공식: (X - min)/(max - min)",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 57,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 24,
    "question": "원-핫 인코딩(One-Hot Encoding)에 대한 설명으로 옳은 것은?",
    "options": [
      "수치형 데이터를 범주형으로 변환한다",
      "범주형 데이터를 0과 1로 이루어진 벡터로 변환한다",
      "연속형 데이터를 구간별로 나눈다",
      "결측값을 평균으로 대체한다"
    ],
    "correct": 1,
    "explanation": "원-핫 인코딩은 범주형 데이터를 0과 1로 이루어진 벡터로 변환하는 방법입니다. 각 범주마다 새로운 이진 변수를 생성합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 58,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 25,
    "question": "PCA(주성분 분석)의 목적은?",
    "options": [
      "데이터 양을 증가시킨다",
      "차원을 축소한다",
      "결측값을 처리한다",
      "이상값을 제거한다"
    ],
    "correct": 1,
    "explanation": "PCA(Principal Component Analysis)는 고차원 데이터를 저차원으로 축소하여 차원의 저주를 해결하고 계산 효율성을 높이는 기법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 59,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 26,
    "question": "피어슨 상관계수의 범위는?",
    "options": [
      "[0, 1]",
      "[-1, 1]",
      "[0, ∞]",
      "[-∞, ∞]"
    ],
    "correct": 1,
    "explanation": "피어슨 상관계수는 -1과 1 사이의 값을 가집니다. -1에 가까우면 강한 음의 상관관계, 1에 가까우면 강한 양의 상관관계, 0에 가까우면 상관관계가 없음을 의미합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 60,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 27,
    "question": "첨도(Kurtosis)가 3보다 클 때 분포의 특징은?",
    "options": [
      "평평한 분포",
      "뾰족한 분포",
      "치우친 분포",
      "정규 분포"
    ],
    "correct": 1,
    "explanation": "첨도가 3보다 크면 뾰족한 분포(leptokurtic), 3보다 작으면 평평한 분포(platykurtic), 3이면 정규분포(mesokurtic)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 61,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 28,
    "question": "왜도(Skewness)가 0보다 클 때 분포의 특징은?",
    "options": [
      "좌편향 분포",
      "우편향 분포",
      "정규 분포",
      "이봉 분포"
    ],
    "correct": 1,
    "explanation": "왜도가 0보다 크면 우편향(right-skewed) 분포, 0보다 작으면 좌편향(left-skewed) 분포, 0이면 대칭 분포입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 62,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 29,
    "question": "중심극한정리에서 표본 크기가 얼마 이상일 때 정규분포에 근사한다고 보는가?",
    "options": [
      "20",
      "30",
      "50",
      "100"
    ],
    "correct": 1,
    "explanation": "중심극한정리에 의하면 표본 크기가 30 이상일 때 표본평균의 분포가 정규분포에 근사한다고 봅니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 63,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 30,
    "question": "표준오차(Standard Error)를 구하는 공식에서 분모는?",
    "options": [
      "표본 크기",
      "표본 크기의 제곱근",
      "표준편차",
      "분산"
    ],
    "correct": 1,
    "explanation": "표준오차 = σ/√n (σ: 모표준편차, n: 표본크기) 또는 s/√n (s: 표본표준편차)입니다. 분모는 표본 크기의 제곱근입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 64,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 31,
    "question": "95% 신뢰구간에서 사용하는 Z값은?",
    "options": [
      "1.64",
      "1.96",
      "2.33",
      "2.58"
    ],
    "correct": 1,
    "explanation": "95% 신뢰구간에서는 α=0.05이므로 α/2=0.025입니다. 따라서 Z_{0.025} = 1.96을 사용합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 65,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 32,
    "question": "가설검정에서 1종 오류(Type I Error)는?",
    "options": [
      "귀무가설이 참인데 귀무가설을 기각하는 오류",
      "귀무가설이 거짓인데 귀무가설을 채택하는 오류",
      "대립가설이 참인데 대립가설을 기각하는 오류",
      "대립가설이 거짓인데 대립가설을 채택하는 오류"
    ],
    "correct": 0,
    "explanation": "1종 오류(Type I Error)는 귀무가설이 참인데 이를 기각하는 오류입니다. 2종 오류(Type II Error)는 귀무가설이 거짓인데 이를 채택하는 오류입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 66,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 33,
    "question": "층화표집(Stratified Sampling)에 대한 설명으로 옳은 것은?",
    "options": [
      "모집단을 동질적인 계층으로 나누어 각 계층에서 표본을 추출한다",
      "모집단을 지역별로 나누어 일부 지역을 선택한다",
      "체계적으로 일정한 간격으로 표본을 추출한다",
      "완전히 무작위로 표본을 추출한다"
    ],
    "correct": 0,
    "explanation": "층화표집은 모집단을 특성이 비슷한 몇 개의 계층(strata)으로 나눈 후, 각 계층에서 표본을 추출하는 방법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 67,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 34,
    "question": "베이즈 정리에서 P(A|B) × P(B) = ?",
    "options": [
      "P(B|A)",
      "P(A∩B)",
      "P(A∪B)",
      "P(A) × P(B)"
    ],
    "correct": 1,
    "explanation": "베이즈 정리: P(A|B) = P(B|A) × P(A) / P(B)에서 P(A|B) × P(B) = P(B|A) × P(A) = P(A∩B)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 68,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 35,
    "question": "Forward Selection 변수 선택법의 특징은?",
    "options": [
      "모든 변수로 시작하여 제거해 나간다",
      "변수 없이 시작하여 추가해 나간다",
      "전진과 후진을 반복한다",
      "무작위로 변수를 선택한다"
    ],
    "correct": 1,
    "explanation": "Forward Selection은 변수 없이 시작하여 유의한 변수를 하나씩 추가해 나가는 방법입니다. Backward Elimination은 모든 변수로 시작하여 제거해 나갑니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 69,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 36,
    "question": "불균형 데이터 처리 방법이 아닌 것은?",
    "options": [
      "Under-sampling",
      "Over-sampling",
      "Weight Balancing",
      "Data Normalization"
    ],
    "correct": 3,
    "explanation": "불균형 데이터 처리 방법에는 Under-sampling(다수 클래스 축소), Over-sampling(소수 클래스 확대), Weight Balancing(가중치 조정) 등이 있습니다. Data Normalization은 스케일링 기법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 70,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 37,
    "question": "SMOTE 기법에 대한 설명으로 옳은 것은?",
    "options": [
      "Under-sampling 기법이다",
      "Over-sampling 기법이다",
      "정규화 기법이다",
      "차원축소 기법이다"
    ],
    "correct": 1,
    "explanation": "SMOTE(Synthetic Minority Oversampling Technique)는 소수 클래스의 합성 데이터를 생성하여 데이터 불균형을 해결하는 Over-sampling 기법입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 71,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 기획",
    "question_number": 38,
    "question": "t-검정에서 사용하는 분포는?",
    "options": [
      "정규분포",
      "t-분포",
      "카이제곱분포",
      "F-분포"
    ],
    "correct": 1,
    "explanation": "t-검정은 모표준편차를 모를 때 사용하며, t-분포를 따릅니다. 표본 크기가 클수록 정규분포에 근사합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 72,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 39,
    "question": "회귀분석에서 R-squared가 의미하는 것은?",
    "options": [
      "오차의 제곱합",
      "총변동에 대한 회귀변동의 비율",
      "독립변수의 개수",
      "표본의 크기"
    ],
    "correct": 1,
    "explanation": "R-squared(결정계수)는 총변동에 대한 회귀변동의 비율로, 독립변수가 종속변수의 변동을 얼마나 설명하는지를 나타냅니다. R² = SSR/SST",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 73,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 40,
    "question": "로지스틱 회귀에서 사용하는 활성화 함수는?",
    "options": [
      "ReLU",
      "Sigmoid",
      "Tanh",
      "Linear"
    ],
    "correct": 1,
    "explanation": "로지스틱 회귀에서는 Sigmoid 함수를 사용하여 선형 조합을 0과 1 사이의 확률값으로 변환합니다. Sigmoid(z) = 1/(1+e^(-z))",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 74,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 41,
    "question": "의사결정나무에서 과적합을 방지하는 방법이 아닌 것은?",
    "options": [
      "가지치기(Pruning)",
      "정지규칙(Stopping Rule)",
      "최대 깊이 제한",
      "학습률 조정"
    ],
    "correct": 3,
    "explanation": "의사결정나무에서 과적합 방지 방법에는 가지치기, 정지규칙, 최대 깊이 제한, 최소 분할 샘플 수 설정 등이 있습니다. 학습률 조정은 신경망에서 사용하는 방법입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 75,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 42,
    "question": "신경망에서 ReLU 함수의 특징으로 옳지 않은 것은?",
    "options": [
      "계산이 간단하다",
      "기울기 소실 문제를 완화한다",
      "음수 입력에 대해 0을 출력한다",
      "모든 범위에서 미분 가능하다"
    ],
    "correct": 3,
    "explanation": "ReLU 함수는 x=0에서 미분이 불가능합니다. ReLU(x) = max(0, x)로 정의되며, x < 0일 때 0, x > 0일 때 x를 출력합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 76,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 43,
    "question": "SVM에서 커널 함수의 역할은?",
    "options": [
      "선형 분리 가능한 데이터만 처리한다",
      "비선형 데이터를 고차원 공간으로 매핑한다",
      "학습 속도를 향상시킨다",
      "메모리 사용량을 줄인다"
    ],
    "correct": 1,
    "explanation": "SVM의 커널 함수는 비선형 데이터를 고차원 특성 공간으로 매핑하여 선형 분리 가능하게 만드는 역할을 합니다. 대표적으로 RBF, 다항식, 시그모이드 커널이 있습니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 77,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 44,
    "question": "연관규칙에서 지지도(Support)의 정의는?",
    "options": [
      "P(A∩B)/P(A)",
      "P(A∩B)",
      "P(A∩B)/P(B)",
      "P(A)×P(B)"
    ],
    "correct": 1,
    "explanation": "지지도(Support)는 P(A∩B)로 정의됩니다. 신뢰도(Confidence)는 P(B|A) = P(A∩B)/P(A), 향상도(Lift)는 P(B|A)/P(B)입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 78,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 45,
    "question": "K-Means 클러스터링에서 K를 결정하는 방법으로 적절한 것은?",
    "options": [
      "실루엣 분석",
      "엘보우 방법",
      "WCSS 분석",
      "모두 맞다"
    ],
    "correct": 3,
    "explanation": "K-Means에서 최적의 K를 결정하는 방법에는 엘보우 방법(Elbow Method), 실루엣 분석(Silhouette Analysis), WCSS 분석 등이 모두 사용됩니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 79,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 46,
    "question": "DBSCAN 클러스터링의 매개변수가 아닌 것은?",
    "options": [
      "eps (반경)",
      "min_samples (최소 점의 수)",
      "k (클러스터 수)",
      "metric (거리 측정법)"
    ],
    "correct": 2,
    "explanation": "DBSCAN의 주요 매개변수는 eps(이웃을 정의하는 반경), min_samples(핵심점이 되기 위한 최소 이웃 수)입니다. K-Means와 달리 클러스터 수를 미리 정하지 않습니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 80,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 47,
    "question": "시계열 분석에서 정상성(Stationarity)의 조건이 아닌 것은?",
    "options": [
      "평균이 시간에 무관하게 일정하다",
      "분산이 시간에 무관하게 일정하다",
      "자기공분산이 시차에만 의존한다",
      "추세가 지속적으로 증가한다"
    ],
    "correct": 3,
    "explanation": "정상성(Stationarity)의 조건은 ①평균이 시간에 무관하게 일정 ②분산이 시간에 무관하게 일정 ③자기공분산이 시차에만 의존입니다. 추세가 있으면 비정상 시계열입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 81,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 48,
    "question": "ARIMA(p,d,q) 모델에서 'd'가 의미하는 것은?",
    "options": [
      "자기회귀 차수",
      "이동평균 차수",
      "차분 차수",
      "계절성 차수"
    ],
    "correct": 2,
    "explanation": "ARIMA(p,d,q)에서 p는 자기회귀(AR) 차수, d는 차분(Differencing) 차수, q는 이동평균(MA) 차수를 의미합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 82,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 49,
    "question": "베이지안 분류에서 나이브(Naive)의 의미는?",
    "options": [
      "단순함",
      "독립성 가정",
      "확률적",
      "조건부"
    ],
    "correct": 1,
    "explanation": "나이브 베이즈에서 '나이브(Naive)'는 모든 특성들이 서로 독립이라고 가정하는 것을 의미합니다. 이는 현실적이지 않은 가정이지만 계산을 단순화합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 83,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 50,
    "question": "CNN에서 컨볼루션 연산의 목적은?",
    "options": [
      "차원을 축소한다",
      "지역적 특징을 추출한다",
      "과적합을 방지한다",
      "계산량을 줄인다"
    ],
    "correct": 1,
    "explanation": "CNN의 컨볼루션 연산은 필터(커널)를 사용하여 입력 데이터의 지역적 특징(local features)을 추출하는 역할을 합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 84,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 51,
    "question": "RNN에서 장기 의존성 문제를 해결하는 모델은?",
    "options": [
      "LSTM",
      "CNN",
      "SVM",
      "Decision Tree"
    ],
    "correct": 0,
    "explanation": "LSTM(Long Short-Term Memory)은 RNN의 장기 의존성 문제와 기울기 소실 문제를 해결하기 위해 개발된 모델입니다. GRU도 유사한 목적으로 사용됩니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 85,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 52,
    "question": "랜덤 포레스트의 특징으로 옳지 않은 것은?",
    "options": [
      "배깅(Bagging) 기법을 사용한다",
      "여러 의사결정나무를 결합한다",
      "과적합에 강하다",
      "선형 모델이다"
    ],
    "correct": 3,
    "explanation": "랜덤 포레스트는 배깅을 사용한 앙상블 모델로, 여러 의사결정나무를 결합하여 과적합에 강한 특징이 있습니다. 비선형 모델입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 86,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 53,
    "question": "부스팅(Boosting) 앙상블의 특징은?",
    "options": [
      "모델을 독립적으로 학습한다",
      "순차적으로 학습하여 오류를 보완한다",
      "모든 모델에 동일한 가중치를 부여한다",
      "배깅과 동일한 방법이다"
    ],
    "correct": 1,
    "explanation": "부스팅은 모델을 순차적으로 학습하면서 이전 모델의 오류를 다음 모델이 보완하도록 하는 앙상블 기법입니다. 대표적으로 AdaBoost, Gradient Boosting이 있습니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 87,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 54,
    "question": "[변형] 회귀분석에서 R-squared가 의미하는 것은?",
    "options": [
      "오차의 제곱합",
      "총변동에 대한 회귀변동의 비율",
      "독립변수의 개수",
      "표본의 크기"
    ],
    "correct": 1,
    "explanation": "R-squared(결정계수)는 총변동에 대한 회귀변동의 비율로, 독립변수가 종속변수의 변동을 얼마나 설명하는지를 나타냅니다. R² = SSR/SST",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 88,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 55,
    "question": "[변형] 로지스틱 회귀에서 사용하는 활성화 함수는?",
    "options": [
      "ReLU",
      "Sigmoid",
      "Tanh",
      "Linear"
    ],
    "correct": 1,
    "explanation": "로지스틱 회귀에서는 Sigmoid 함수를 사용하여 선형 조합을 0과 1 사이의 확률값으로 변환합니다. Sigmoid(z) = 1/(1+e^(-z))",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 89,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 56,
    "question": "[변형] 의사결정나무에서 과적합을 방지하는 방법이 아닌 것은?",
    "options": [
      "가지치기(Pruning)",
      "정지규칙(Stopping Rule)",
      "최대 깊이 제한",
      "학습률 조정"
    ],
    "correct": 3,
    "explanation": "의사결정나무에서 과적합 방지 방법에는 가지치기, 정지규칙, 최대 깊이 제한, 최소 분할 샘플 수 설정 등이 있습니다. 학습률 조정은 신경망에서 사용하는 방법입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 90,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 모델링",
    "question_number": 57,
    "question": "[변형] 신경망에서 ReLU 함수의 특징으로 옳지 않은 것은?",
    "options": [
      "계산이 간단하다",
      "기울기 소실 문제를 완화한다",
      "음수 입력에 대해 0을 출력한다",
      "모든 범위에서 미분 가능하다"
    ],
    "correct": 3,
    "explanation": "ReLU 함수는 x=0에서 미분이 불가능합니다. ReLU(x) = max(0, x)로 정의되며, x < 0일 때 0, x > 0일 때 x를 출력합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 91,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 결과해석",
    "question_number": 58,
    "question": "혼동행렬에서 Precision(정밀도)을 구하는 공식은?",
    "options": [
      "TP / (TP + FN)",
      "TP / (TP + FP)",
      "TN / (TN + FP)",
      "TN / (TN + FN)"
    ],
    "correct": 1,
    "explanation": "정밀도(Precision) = TP / (TP + FP)입니다. 예측한 양성 중에서 실제 양성인 비율을 의미합니다. 재현율(Recall) = TP / (TP + FN)입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 92,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 결과해석",
    "question_number": 59,
    "question": "F1-score는 다음 중 어떤 두 지표의 조화평균인가?",
    "options": [
      "Accuracy와 Precision",
      "Precision과 Recall",
      "Recall과 Specificity",
      "Accuracy와 Recall"
    ],
    "correct": 1,
    "explanation": "F1-score는 정밀도(Precision)와 재현율(Recall)의 조화평균입니다. F1 = 2 × (Precision × Recall) / (Precision + Recall)",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 93,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 결과해석",
    "question_number": 60,
    "question": "ROC 곡선의 x축과 y축은?",
    "options": [
      "FPR, TPR",
      "TPR, FPR",
      "Precision, Recall",
      "Accuracy, F1-score"
    ],
    "correct": 0,
    "explanation": "ROC 곡선의 x축은 FPR(False Positive Rate), y축은 TPR(True Positive Rate)입니다. FPR = FP/(FP+TN), TPR = TP/(TP+FN)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 94,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 결과해석",
    "question_number": 61,
    "question": "AUC 값이 0.5에 가까울 때의 의미는?",
    "options": [
      "완벽한 분류기",
      "매우 좋은 분류기",
      "무작위 분류기 수준",
      "최악의 분류기"
    ],
    "correct": 2,
    "explanation": "AUC(Area Under the Curve) 값이 0.5는 무작위 분류기 수준을 의미합니다. 1에 가까울수록 좋은 분류기, 0.8~0.9면 우수한 분류기로 평가합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 95,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 결과해석",
    "question_number": 62,
    "question": "회귀 모델의 평가지표 중 RMSE는 무엇의 약자인가?",
    "options": [
      "Root Mean Square Error",
      "Relative Mean Square Error",
      "Random Mean Square Error",
      "Robust Mean Square Error"
    ],
    "correct": 0,
    "explanation": "RMSE는 Root Mean Square Error(평균제곱근오차)의 약자입니다. MSE에 제곱근을 취한 값으로, 실제값과 예측값의 차이를 나타냅니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 96,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 결과해석",
    "question_number": 63,
    "question": "실루엣 계수(Silhouette Coefficient)의 범위는?",
    "options": [
      "[0, 1]",
      "[-1, 1]",
      "[0, ∞]",
      "[-∞, ∞]"
    ],
    "correct": 1,
    "explanation": "실루엣 계수는 -1과 1 사이의 값을 가집니다. 1에 가까우면 잘 분류됨, 0에 가까우면 경계에 있음, -1에 가까우면 잘못 분류됨을 의미합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 97,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 결과해석",
    "question_number": 64,
    "question": "K-Fold 교차검증에서 K=5일 때 훈련 데이터의 비율은?",
    "options": [
      "20%",
      "40%",
      "60%",
      "80%"
    ],
    "correct": 3,
    "explanation": "K-Fold 교차검증에서 K=5이면 데이터를 5등분하여 1개를 검증용(20%), 4개를 훈련용(80%)으로 사용합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 98,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 결과해석",
    "question_number": 65,
    "question": "과적합(Overfitting)을 방지하는 방법이 아닌 것은?",
    "options": [
      "Dropout",
      "L2 Regularization",
      "더 복잡한 모델 사용",
      "Early Stopping"
    ],
    "correct": 2,
    "explanation": "과적합 방지 방법에는 Dropout, 정규화(L1/L2), Early Stopping, 데이터 증강 등이 있습니다. 더 복잡한 모델을 사용하면 과적합이 더 심해집니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 99,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 결과해석",
    "question_number": 66,
    "question": "GridSearchCV의 목적은?",
    "options": [
      "과적합을 방지한다",
      "하이퍼파라미터를 최적화한다",
      "특성을 선택한다",
      "데이터를 전처리한다"
    ],
    "correct": 1,
    "explanation": "GridSearchCV는 하이퍼파라미터의 최적 조합을 찾기 위해 격자 탐색(Grid Search)과 교차검증을 결합한 방법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 100,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 결과해석",
    "question_number": 67,
    "question": "시각화에서 산점도(Scatter Plot)가 가장 적합한 용도는?",
    "options": [
      "범주별 빈도 비교",
      "두 연속형 변수의 상관관계",
      "시간에 따른 변화",
      "분포의 형태"
    ],
    "correct": 1,
    "explanation": "산점도는 두 연속형 변수 간의 상관관계나 패턴을 시각화하는 데 가장 적합합니다. 막대그래프는 범주별 비교, 선그래프는 시간 변화, 히스토그램은 분포 형태에 적합합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 101,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 결과해석",
    "question_number": 68,
    "question": "Confusion Matrix에서 Type I Error는?",
    "options": [
      "True Positive",
      "True Negative",
      "False Positive",
      "False Negative"
    ],
    "correct": 2,
    "explanation": "Type I Error는 False Positive(FP)로, 실제로는 음성인데 양성으로 잘못 분류한 경우입니다. Type II Error는 False Negative(FN)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 102,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 결과해석",
    "question_number": 69,
    "question": "Bootstrap 샘플링에서 Out-of-Bag 비율은 약 얼마인가?",
    "options": [
      "36.8%",
      "50%",
      "63.2%",
      "70%"
    ],
    "correct": 0,
    "explanation": "Bootstrap 샘플링에서 복원추출로 인해 선택되지 않을 확률은 약 36.8%입니다. 이를 Out-of-Bag(OOB) 샘플이라고 합니다.",
    "difficulty": "★★★★★",
    "difficulty_level": 5
  },
  {
    "id": 103,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 결과해석",
    "question_number": 70,
    "question": "L2 정규화(Ridge)에서 람다(λ) 값이 클수록?",
    "options": [
      "과적합이 증가한다",
      "모델 복잡도가 증가한다",
      "가중치 감소 효과가 커진다",
      "정확도가 항상 향상된다"
    ],
    "correct": 2,
    "explanation": "L2 정규화에서 λ 값이 클수록 가중치를 더 많이 감소시켜 모델을 단순하게 만들고 과적합을 방지합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 104,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 결과해석",
    "question_number": 71,
    "question": "Adjusted R-squared가 R-squared보다 낮은 이유는?",
    "options": [
      "계산 오류",
      "독립변수 개수에 대한 페널티",
      "종속변수의 영향",
      "표본 크기의 영향"
    ],
    "correct": 1,
    "explanation": "Adjusted R-squared는 독립변수의 개수가 증가할 때 발생하는 R-squared의 과대추정을 보정하기 위해 독립변수 개수에 대한 페널티를 부과합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 105,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 결과해석",
    "question_number": 72,
    "question": "엘보우 방법(Elbow Method)이 사용되는 목적은?",
    "options": [
      "최적의 학습률 찾기",
      "최적의 클러스터 수 결정",
      "특성 선택",
      "모델 성능 평가"
    ],
    "correct": 1,
    "explanation": "엘보우 방법은 K-Means 클러스터링에서 최적의 클러스터 수(K)를 결정하기 위해 WCSS(Within-Cluster Sum of Squares)의 변화를 관찰하는 방법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 106,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 결과해석",
    "question_number": 73,
    "question": "[변형] 혼동행렬에서 Precision(정밀도)을 구하는 공식은?",
    "options": [
      "TP / (TP + FN)",
      "TP / (TP + FP)",
      "TN / (TN + FP)",
      "TN / (TN + FN)"
    ],
    "correct": 1,
    "explanation": "정밀도(Precision) = TP / (TP + FP)입니다. 예측한 양성 중에서 실제 양성인 비율을 의미합니다. 재현율(Recall) = TP / (TP + FN)입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 107,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 결과해석",
    "question_number": 74,
    "question": "[변형] F1-score는 다음 중 어떤 두 지표의 조화평균인가?",
    "options": [
      "Accuracy와 Precision",
      "Precision과 Recall",
      "Recall과 Specificity",
      "Accuracy와 Recall"
    ],
    "correct": 1,
    "explanation": "F1-score는 정밀도(Precision)와 재현율(Recall)의 조화평균입니다. F1 = 2 × (Precision × Recall) / (Precision + Recall)",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 108,
    "type": "예상문제",
    "round": "1회차",
    "section": "빅데이터 결과해석",
    "question_number": 75,
    "question": "[변형] ROC 곡선의 x축과 y축은?",
    "options": [
      "FPR, TPR",
      "TPR, FPR",
      "Precision, Recall",
      "Accuracy, F1-score"
    ],
    "correct": 0,
    "explanation": "ROC 곡선의 x축은 FPR(False Positive Rate), y축은 TPR(True Positive Rate)입니다. FPR = FP/(FP+TN), TPR = TP/(TP+FN)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 109,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 1,
    "question": "스키마 온 라이트(Schema on Write)와 스키마 온 리드(Schema on Read)에 대한 설명으로 옳은 것은?",
    "options": [
      "둘 다 동일한 개념이다",
      "스키마 온 라이트는 NoSQL에서 주로 사용된다",
      "스키마 온 리드는 RDBMS에서 주로 사용된다",
      "스키마 온 리드는 데이터를 읽을 때 스키마를 정의한다"
    ],
    "correct": 3,
    "explanation": "스키마 온 라이트는 데이터를 저장할 때 스키마를 정의하는 방식(RDBMS)이고, 스키마 온 리드는 데이터를 읽을 때 스키마를 정의하는 방식(NoSQL, 빅데이터)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 110,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 2,
    "question": "클라우드 컴퓨팅의 서비스 모델 중 PaaS는 무엇의 약자인가?",
    "options": [
      "Platform as a Service",
      "Program as a Service",
      "Process as a Service",
      "Performance as a Service"
    ],
    "correct": 0,
    "explanation": "클라우드 컴퓨팅의 서비스 모델은 IaaS(Infrastructure as a Service), PaaS(Platform as a Service), SaaS(Software as a Service)가 있습니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 111,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 3,
    "question": "[변형] 빅데이터의 5V 중 '신뢰성'을 의미하는 것은?",
    "options": [
      "Volume",
      "Velocity",
      "Variety",
      "Veracity"
    ],
    "correct": 3,
    "explanation": "빅데이터의 5V는 Volume(규모), Velocity(속도), Variety(다양성), Value(가치), Veracity(신뢰성)입니다. Veracity는 데이터의 정확성과 신뢰성을 의미합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 112,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 4,
    "question": "[변형] DIKW 피라미드에서 가장 상위 단계는?",
    "options": [
      "Data",
      "Information",
      "Knowledge",
      "Wisdom"
    ],
    "correct": 3,
    "explanation": "DIKW 피라미드는 Data → Information → Knowledge → Wisdom 순으로 구성되며, Wisdom(지혜)이 가장 상위 단계입니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 113,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 5,
    "question": "[변형] SECI 모델에서 형식지를 암묵지로 변환하는 과정은?",
    "options": [
      "공통화(Socialization)",
      "표출화(Externalization)",
      "연결화(Combination)",
      "내면화(Internalization)"
    ],
    "correct": 3,
    "explanation": "SECI 모델에서 내면화(Internalization)는 형식지를 암묵지로 변환하는 과정입니다. 공통화는 암묵지→암묵지, 표출화는 암묵지→형식지, 연결화는 형식지→형식지입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 114,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 6,
    "question": "[변형] NoSQL DBMS의 특징으로 옳지 않은 것은?",
    "options": [
      "비정형 데이터 저장 및 관리에 적합하다",
      "형식에 얽매이지 않는다",
      "테이블 형태로 데이터를 정리한다",
      "인스타그램, 유튜브 등에서 사용한다"
    ],
    "correct": 2,
    "explanation": "NoSQL DBMS는 비정형 데이터 저장에 적합하고 형식에 얽매이지 않는 특징이 있습니다. 테이블 형태로 데이터를 정리하는 것은 관계형 DBMS(RDBMS)의 특징입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 115,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 7,
    "question": "[변형] 데이터베이스의 특징을 나타내는 '공통 저변'에서 '저'가 의미하는 것은?",
    "options": [
      "공용 데이터",
      "통합된 데이터",
      "저장된 데이터",
      "변화되는 데이터"
    ],
    "correct": 2,
    "explanation": "데이터베이스의 특징 '공통 저변'은 공용 데이터, 통합된 데이터, 저장된 데이터, 변화되는 데이터를 의미합니다. '저'는 저장된 데이터를 나타냅니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 116,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 8,
    "question": "[변형] 빅데이터 활용을 위한 3대 요소는?",
    "options": [
      "인력, 자원, 기술",
      "수집, 저장, 분석",
      "정형, 반정형, 비정형",
      "Volume, Velocity, Variety"
    ],
    "correct": 0,
    "explanation": "빅데이터 활용을 위한 3대 요소는 인력(분석 전문가), 자원(데이터 및 하드웨어), 기술(분석 기술 및 도구)입니다. 암기 팁으로 '인자기'를 사용할 수 있습니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 117,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 9,
    "question": "[변형] OLTP에 대한 설명으로 옳은 것은?",
    "options": [
      "대화식 분석 처리",
      "거래 단위 트랜잭션 처리",
      "고객 관계 관리",
      "공급망 관리"
    ],
    "correct": 1,
    "explanation": "OLTP(Online Transaction Processing)는 거래 단위 트랜잭션 처리를 의미합니다. OLAP는 대화식 분석 처리, CRM은 고객 관계 관리, SCM은 공급망 관리입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 118,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 10,
    "question": "[변형] 메타데이터(Metadata)에 대한 설명으로 옳은 것은?",
    "options": [
      "데이터를 설명하기 위한 데이터",
      "데이터의 타입과 값을 정의",
      "DB에 대한 전반적인 명세",
      "정렬 탐색을 위한 데이터의 이름"
    ],
    "correct": 0,
    "explanation": "메타데이터(Metadata)는 데이터를 설명하기 위한 데이터입니다. 인스턴스는 데이터 타입과 값을 정의, 스키마는 DB에 대한 전반적인 명세, 인덱스는 정렬 탐색을 위한 데이터의 이름입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 119,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 11,
    "question": "[변형] 개인정보 비식별화 기법이 아닌 것은?",
    "options": [
      "가명 처리",
      "총계 처리",
      "데이터 마스킹",
      "데이터 암호화"
    ],
    "correct": 3,
    "explanation": "개인정보 비식별화 기법에는 가명처리, 총계처리, 데이터 마스킹, 특이화(일반화), 범주화 등이 있습니다. 데이터 암호화는 개인정보 보호 기법이지만 비식별화 기법은 아닙니다.",
    "difficulty": "★★★★★",
    "difficulty_level": 5
  },
  {
    "id": 120,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 12,
    "question": "[변형] MyData의 3대 원칙은?",
    "options": [
      "수집, 저장, 활용",
      "개인 주도, 시장 주도, 정부 지원",
      "정형, 반정형, 비정형",
      "수집, 전송, 활용"
    ],
    "correct": 1,
    "explanation": "MyData의 3대 원칙은 개인 주도(개인이 본인 데이터 활용 직접 결정), 시장 주도(민간이 주도하는 데이터 경제), 정부 지원(제도·기술적 기반 마련)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 121,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 13,
    "question": "[변형] 하둡(Hadoop) HDFS의 특징으로 옳지 않은 것은?",
    "options": [
      "분산 저장이 가능하다",
      "높은 내결함성을 제공한다",
      "단일 장애점이 존재한다",
      "대용량 데이터 처리에 최적화되어 있다"
    ],
    "correct": 2,
    "explanation": "하둡 HDFS는 분산 저장, 높은 내결함성, 대용량 데이터 처리에 최적화된 특징이 있습니다. 단일 장애점(Single Point of Failure)을 해결하는 것이 HDFS의 주요 목적 중 하나입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 122,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 14,
    "question": "[변형] 데이터 웨어하우스(Data Warehouse)의 특징이 아닌 것은?",
    "options": [
      "주제 지향적(Subject-Oriented)",
      "통합적(Integrated)",
      "시간 변동적(Time-Variant)",
      "실시간 처리(Real-time Processing)"
    ],
    "correct": 3,
    "explanation": "데이터 웨어하우스의 특징은 주제 지향적, 통합적, 시간 변동적, 비휘발적(Non-Volatile)입니다. 실시간 처리보다는 배치 처리에 최적화되어 있습니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 123,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 15,
    "question": "[변형] ETL 프로세스에서 'T'가 의미하는 것은?",
    "options": [
      "Transfer",
      "Transform",
      "Transmit",
      "Transpose"
    ],
    "correct": 1,
    "explanation": "ETL은 Extraction(추출), Transformation(변환), Loading(적재)의 약자입니다. 'T'는 Transform(변환)을 의미합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 124,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 16,
    "question": "[변형] CRISP-DM 방법론의 6단계 중 첫 번째 단계는?",
    "options": [
      "데이터 이해",
      "비즈니스 이해",
      "데이터 준비",
      "모델링"
    ],
    "correct": 1,
    "explanation": "CRISP-DM 방법론의 6단계는 ①비즈니스 이해 ②데이터 이해 ③데이터 준비 ④모델링 ⑤평가 ⑥배포 순서입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 125,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 17,
    "question": "[변형] KDD(Knowledge Discovery in Databases) 프로세스에서 첫 번째 단계는?",
    "options": [
      "Selection",
      "Preprocessing",
      "Transformation",
      "Data Mining"
    ],
    "correct": 0,
    "explanation": "KDD 프로세스는 ①선택(Selection) ②전처리(Preprocessing) ③변환(Transformation) ④데이터마이닝(Data Mining) ⑤해석/평가(Interpretation/Evaluation) 순서입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 126,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 18,
    "question": "[변형] 빅데이터 분석 프로젝트에서 Problem Discovery 단계에 해당하지 않는 것은?",
    "options": [
      "What (무엇을)",
      "Why (왜)",
      "How (어떻게)",
      "When (언제)"
    ],
    "correct": 2,
    "explanation": "Problem Discovery 단계에서는 What(무엇을), Why(왜), When(언제)를 중점적으로 다룹니다. How(어떻게)는 Solution Search 단계에서 다루어집니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 127,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 개론",
    "question_number": 19,
    "question": "[변형] STEEP 분석에서 'E'가 두 번 나오는데, 이 두 'E'가 의미하는 것은?",
    "options": [
      "Economic, Environmental",
      "Educational, Ethical",
      "Electronic, Emotional",
      "Efficient, Effective"
    ],
    "correct": 0,
    "explanation": "STEEP 분석은 Social(사회적), Technological(기술적), Economic(경제적), Environmental(환경적), Political(정치적) 요인을 분석하는 기법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 128,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 20,
    "question": "t-검정에서 사용하는 분포는?",
    "options": [
      "정규분포",
      "t-분포",
      "카이제곱분포",
      "F-분포"
    ],
    "correct": 1,
    "explanation": "t-검정은 모표준편차를 모를 때 사용하며, t-분포를 따릅니다. 표본 크기가 클수록 정규분포에 근사합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 129,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 21,
    "question": "다중공선성(Multicollinearity) 진단 지표로 사용되는 것은?",
    "options": [
      "R-squared",
      "VIF",
      "AIC",
      "MSE"
    ],
    "correct": 1,
    "explanation": "VIF(Variance Inflation Factor)는 다중공선성을 진단하는 지표입니다. 일반적으로 VIF > 10이면 심각한 다중공선성이 있다고 판단합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 130,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 22,
    "question": "[변형] 결측값 처리 방법 중 MCAR은 무엇의 약자인가?",
    "options": [
      "Missing Completely At Random",
      "Missing Conditionally At Random",
      "Missing Constantly At Random",
      "Missing Correctly At Random"
    ],
    "correct": 0,
    "explanation": "MCAR은 Missing Completely At Random의 약자로, 결측값이 완전히 무작위로 발생한 경우를 의미합니다. MAR(Missing At Random), MNAR(Missing Not At Random)과 구별됩니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 131,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 23,
    "question": "[변형] 이상값 탐지 방법 중 IQR을 이용한 방법에서 이상값의 기준은?",
    "options": [
      "Q1 - 1.0×IQR 미만, Q3 + 1.0×IQR 초과",
      "Q1 - 1.5×IQR 미만, Q3 + 1.5×IQR 초과",
      "Q1 - 2.0×IQR 미만, Q3 + 2.0×IQR 초과",
      "Q1 - 3.0×IQR 미만, Q3 + 3.0×IQR 초과"
    ],
    "correct": 1,
    "explanation": "IQR(Inter Quartile Range) 방법에서는 Q1 - 1.5×IQR 미만이거나 Q3 + 1.5×IQR 초과하는 값을 이상값으로 판단합니다. IQR = Q3 - Q1입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 132,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 24,
    "question": "[변형] Z-score 정규화 공식에서 분모에 해당하는 것은?",
    "options": [
      "평균",
      "최댓값",
      "표준편차",
      "중앙값"
    ],
    "correct": 2,
    "explanation": "Z-score 정규화는 Z = (X - μ)/σ 공식을 사용합니다. 여기서 μ는 평균, σ는 표준편차입니다. 표준편차가 분모에 해당합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 133,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 25,
    "question": "[변형] Min-Max 정규화의 결과 범위는?",
    "options": [
      "[-1, 1]",
      "[0, 1]",
      "[-∞, ∞]",
      "[0, 100]"
    ],
    "correct": 1,
    "explanation": "Min-Max 정규화는 데이터를 0과 1 사이의 값으로 변환하는 방법입니다. 공식: (X - min)/(max - min)",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 134,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 26,
    "question": "[변형] 원-핫 인코딩(One-Hot Encoding)에 대한 설명으로 옳은 것은?",
    "options": [
      "수치형 데이터를 범주형으로 변환한다",
      "범주형 데이터를 0과 1로 이루어진 벡터로 변환한다",
      "연속형 데이터를 구간별로 나눈다",
      "결측값을 평균으로 대체한다"
    ],
    "correct": 1,
    "explanation": "원-핫 인코딩은 범주형 데이터를 0과 1로 이루어진 벡터로 변환하는 방법입니다. 각 범주마다 새로운 이진 변수를 생성합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 135,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 27,
    "question": "[변형] PCA(주성분 분석)의 목적은?",
    "options": [
      "데이터 양을 증가시킨다",
      "차원을 축소한다",
      "결측값을 처리한다",
      "이상값을 제거한다"
    ],
    "correct": 1,
    "explanation": "PCA(Principal Component Analysis)는 고차원 데이터를 저차원으로 축소하여 차원의 저주를 해결하고 계산 효율성을 높이는 기법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 136,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 28,
    "question": "[변형] 피어슨 상관계수의 범위는?",
    "options": [
      "[0, 1]",
      "[-1, 1]",
      "[0, ∞]",
      "[-∞, ∞]"
    ],
    "correct": 1,
    "explanation": "피어슨 상관계수는 -1과 1 사이의 값을 가집니다. -1에 가까우면 강한 음의 상관관계, 1에 가까우면 강한 양의 상관관계, 0에 가까우면 상관관계가 없음을 의미합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 137,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 29,
    "question": "[변형] 첨도(Kurtosis)가 3보다 클 때 분포의 특징은?",
    "options": [
      "평평한 분포",
      "뾰족한 분포",
      "치우친 분포",
      "정규 분포"
    ],
    "correct": 1,
    "explanation": "첨도가 3보다 크면 뾰족한 분포(leptokurtic), 3보다 작으면 평평한 분포(platykurtic), 3이면 정규분포(mesokurtic)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 138,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 30,
    "question": "[변형] 왜도(Skewness)가 0보다 클 때 분포의 특징은?",
    "options": [
      "좌편향 분포",
      "우편향 분포",
      "정규 분포",
      "이봉 분포"
    ],
    "correct": 1,
    "explanation": "왜도가 0보다 크면 우편향(right-skewed) 분포, 0보다 작으면 좌편향(left-skewed) 분포, 0이면 대칭 분포입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 139,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 31,
    "question": "[변형] 중심극한정리에서 표본 크기가 얼마 이상일 때 정규분포에 근사한다고 보는가?",
    "options": [
      "20",
      "30",
      "50",
      "100"
    ],
    "correct": 1,
    "explanation": "중심극한정리에 의하면 표본 크기가 30 이상일 때 표본평균의 분포가 정규분포에 근사한다고 봅니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 140,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 32,
    "question": "[변형] 표준오차(Standard Error)를 구하는 공식에서 분모는?",
    "options": [
      "표본 크기",
      "표본 크기의 제곱근",
      "표준편차",
      "분산"
    ],
    "correct": 1,
    "explanation": "표준오차 = σ/√n (σ: 모표준편차, n: 표본크기) 또는 s/√n (s: 표본표준편차)입니다. 분모는 표본 크기의 제곱근입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 141,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 33,
    "question": "[변형] 95% 신뢰구간에서 사용하는 Z값은?",
    "options": [
      "1.64",
      "1.96",
      "2.33",
      "2.58"
    ],
    "correct": 1,
    "explanation": "95% 신뢰구간에서는 α=0.05이므로 α/2=0.025입니다. 따라서 Z_{0.025} = 1.96을 사용합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 142,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 34,
    "question": "[변형] 가설검정에서 1종 오류(Type I Error)는?",
    "options": [
      "귀무가설이 참인데 귀무가설을 기각하는 오류",
      "귀무가설이 거짓인데 귀무가설을 채택하는 오류",
      "대립가설이 참인데 대립가설을 기각하는 오류",
      "대립가설이 거짓인데 대립가설을 채택하는 오류"
    ],
    "correct": 0,
    "explanation": "1종 오류(Type I Error)는 귀무가설이 참인데 이를 기각하는 오류입니다. 2종 오류(Type II Error)는 귀무가설이 거짓인데 이를 채택하는 오류입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 143,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 35,
    "question": "[변형] 층화표집(Stratified Sampling)에 대한 설명으로 옳은 것은?",
    "options": [
      "모집단을 동질적인 계층으로 나누어 각 계층에서 표본을 추출한다",
      "모집단을 지역별로 나누어 일부 지역을 선택한다",
      "체계적으로 일정한 간격으로 표본을 추출한다",
      "완전히 무작위로 표본을 추출한다"
    ],
    "correct": 0,
    "explanation": "층화표집은 모집단을 특성이 비슷한 몇 개의 계층(strata)으로 나눈 후, 각 계층에서 표본을 추출하는 방법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 144,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 36,
    "question": "[변형] 베이즈 정리에서 P(A|B) × P(B) = ?",
    "options": [
      "P(B|A)",
      "P(A∩B)",
      "P(A∪B)",
      "P(A) × P(B)"
    ],
    "correct": 1,
    "explanation": "베이즈 정리: P(A|B) = P(B|A) × P(A) / P(B)에서 P(A|B) × P(B) = P(B|A) × P(A) = P(A∩B)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 145,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 37,
    "question": "[변형] Forward Selection 변수 선택법의 특징은?",
    "options": [
      "모든 변수로 시작하여 제거해 나간다",
      "변수 없이 시작하여 추가해 나간다",
      "전진과 후진을 반복한다",
      "무작위로 변수를 선택한다"
    ],
    "correct": 1,
    "explanation": "Forward Selection은 변수 없이 시작하여 유의한 변수를 하나씩 추가해 나가는 방법입니다. Backward Elimination은 모든 변수로 시작하여 제거해 나갑니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 146,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 기획",
    "question_number": 38,
    "question": "[변형] 불균형 데이터 처리 방법이 아닌 것은?",
    "options": [
      "Under-sampling",
      "Over-sampling",
      "Weight Balancing",
      "Data Normalization"
    ],
    "correct": 3,
    "explanation": "불균형 데이터 처리 방법에는 Under-sampling(다수 클래스 축소), Over-sampling(소수 클래스 확대), Weight Balancing(가중치 조정) 등이 있습니다. Data Normalization은 스케일링 기법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 147,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 39,
    "question": "[변형] 신경망에서 ReLU 함수의 특징으로 옳지 않은 것은?",
    "options": [
      "계산이 간단하다",
      "기울기 소실 문제를 완화한다",
      "음수 입력에 대해 0을 출력한다",
      "모든 범위에서 미분 가능하다"
    ],
    "correct": 3,
    "explanation": "ReLU 함수는 x=0에서 미분이 불가능합니다. ReLU(x) = max(0, x)로 정의되며, x < 0일 때 0, x > 0일 때 x를 출력합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 148,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 40,
    "question": "[변형] SVM에서 커널 함수의 역할은?",
    "options": [
      "선형 분리 가능한 데이터만 처리한다",
      "비선형 데이터를 고차원 공간으로 매핑한다",
      "학습 속도를 향상시킨다",
      "메모리 사용량을 줄인다"
    ],
    "correct": 1,
    "explanation": "SVM의 커널 함수는 비선형 데이터를 고차원 특성 공간으로 매핑하여 선형 분리 가능하게 만드는 역할을 합니다. 대표적으로 RBF, 다항식, 시그모이드 커널이 있습니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 149,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 41,
    "question": "[변형] 연관규칙에서 지지도(Support)의 정의는?",
    "options": [
      "P(A∩B)/P(A)",
      "P(A∩B)",
      "P(A∩B)/P(B)",
      "P(A)×P(B)"
    ],
    "correct": 1,
    "explanation": "지지도(Support)는 P(A∩B)로 정의됩니다. 신뢰도(Confidence)는 P(B|A) = P(A∩B)/P(A), 향상도(Lift)는 P(B|A)/P(B)입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 150,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 42,
    "question": "[변형] K-Means 클러스터링에서 K를 결정하는 방법으로 적절한 것은?",
    "options": [
      "실루엣 분석",
      "엘보우 방법",
      "WCSS 분석",
      "모두 맞다"
    ],
    "correct": 3,
    "explanation": "K-Means에서 최적의 K를 결정하는 방법에는 엘보우 방법(Elbow Method), 실루엣 분석(Silhouette Analysis), WCSS 분석 등이 모두 사용됩니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 151,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 43,
    "question": "[변형] DBSCAN 클러스터링의 매개변수가 아닌 것은?",
    "options": [
      "eps (반경)",
      "min_samples (최소 점의 수)",
      "k (클러스터 수)",
      "metric (거리 측정법)"
    ],
    "correct": 2,
    "explanation": "DBSCAN의 주요 매개변수는 eps(이웃을 정의하는 반경), min_samples(핵심점이 되기 위한 최소 이웃 수)입니다. K-Means와 달리 클러스터 수를 미리 정하지 않습니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 152,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 44,
    "question": "[변형] 시계열 분석에서 정상성(Stationarity)의 조건이 아닌 것은?",
    "options": [
      "평균이 시간에 무관하게 일정하다",
      "분산이 시간에 무관하게 일정하다",
      "자기공분산이 시차에만 의존한다",
      "추세가 지속적으로 증가한다"
    ],
    "correct": 3,
    "explanation": "정상성(Stationarity)의 조건은 ①평균이 시간에 무관하게 일정 ②분산이 시간에 무관하게 일정 ③자기공분산이 시차에만 의존입니다. 추세가 있으면 비정상 시계열입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 153,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 45,
    "question": "[변형] ARIMA(p,d,q) 모델에서 'd'가 의미하는 것은?",
    "options": [
      "자기회귀 차수",
      "이동평균 차수",
      "차분 차수",
      "계절성 차수"
    ],
    "correct": 2,
    "explanation": "ARIMA(p,d,q)에서 p는 자기회귀(AR) 차수, d는 차분(Differencing) 차수, q는 이동평균(MA) 차수를 의미합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 154,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 46,
    "question": "[변형] 베이지안 분류에서 나이브(Naive)의 의미는?",
    "options": [
      "단순함",
      "독립성 가정",
      "확률적",
      "조건부"
    ],
    "correct": 1,
    "explanation": "나이브 베이즈에서 '나이브(Naive)'는 모든 특성들이 서로 독립이라고 가정하는 것을 의미합니다. 이는 현실적이지 않은 가정이지만 계산을 단순화합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 155,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 47,
    "question": "[변형] CNN에서 컨볼루션 연산의 목적은?",
    "options": [
      "차원을 축소한다",
      "지역적 특징을 추출한다",
      "과적합을 방지한다",
      "계산량을 줄인다"
    ],
    "correct": 1,
    "explanation": "CNN의 컨볼루션 연산은 필터(커널)를 사용하여 입력 데이터의 지역적 특징(local features)을 추출하는 역할을 합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 156,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 48,
    "question": "[변형] RNN에서 장기 의존성 문제를 해결하는 모델은?",
    "options": [
      "LSTM",
      "CNN",
      "SVM",
      "Decision Tree"
    ],
    "correct": 0,
    "explanation": "LSTM(Long Short-Term Memory)은 RNN의 장기 의존성 문제와 기울기 소실 문제를 해결하기 위해 개발된 모델입니다. GRU도 유사한 목적으로 사용됩니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 157,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 49,
    "question": "[변형] 랜덤 포레스트의 특징으로 옳지 않은 것은?",
    "options": [
      "배깅(Bagging) 기법을 사용한다",
      "여러 의사결정나무를 결합한다",
      "과적합에 강하다",
      "선형 모델이다"
    ],
    "correct": 3,
    "explanation": "랜덤 포레스트는 배깅을 사용한 앙상블 모델로, 여러 의사결정나무를 결합하여 과적합에 강한 특징이 있습니다. 비선형 모델입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 158,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 50,
    "question": "[변형] 부스팅(Boosting) 앙상블의 특징은?",
    "options": [
      "모델을 독립적으로 학습한다",
      "순차적으로 학습하여 오류를 보완한다",
      "모든 모델에 동일한 가중치를 부여한다",
      "배깅과 동일한 방법이다"
    ],
    "correct": 1,
    "explanation": "부스팅은 모델을 순차적으로 학습하면서 이전 모델의 오류를 다음 모델이 보완하도록 하는 앙상블 기법입니다. 대표적으로 AdaBoost, Gradient Boosting이 있습니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 159,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 51,
    "question": "[변형] 회귀분석에서 R-squared가 의미하는 것은?",
    "options": [
      "오차의 제곱합",
      "총변동에 대한 회귀변동의 비율",
      "독립변수의 개수",
      "표본의 크기"
    ],
    "correct": 1,
    "explanation": "R-squared(결정계수)는 총변동에 대한 회귀변동의 비율로, 독립변수가 종속변수의 변동을 얼마나 설명하는지를 나타냅니다. R² = SSR/SST",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 160,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 52,
    "question": "[변형] 로지스틱 회귀에서 사용하는 활성화 함수는?",
    "options": [
      "ReLU",
      "Sigmoid",
      "Tanh",
      "Linear"
    ],
    "correct": 1,
    "explanation": "로지스틱 회귀에서는 Sigmoid 함수를 사용하여 선형 조합을 0과 1 사이의 확률값으로 변환합니다. Sigmoid(z) = 1/(1+e^(-z))",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 161,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 53,
    "question": "[변형] 의사결정나무에서 과적합을 방지하는 방법이 아닌 것은?",
    "options": [
      "가지치기(Pruning)",
      "정지규칙(Stopping Rule)",
      "최대 깊이 제한",
      "학습률 조정"
    ],
    "correct": 3,
    "explanation": "의사결정나무에서 과적합 방지 방법에는 가지치기, 정지규칙, 최대 깊이 제한, 최소 분할 샘플 수 설정 등이 있습니다. 학습률 조정은 신경망에서 사용하는 방법입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 162,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 54,
    "question": "[변형] 신경망에서 ReLU 함수의 특징으로 옳지 않은 것은?",
    "options": [
      "계산이 간단하다",
      "기울기 소실 문제를 완화한다",
      "음수 입력에 대해 0을 출력한다",
      "모든 범위에서 미분 가능하다"
    ],
    "correct": 3,
    "explanation": "ReLU 함수는 x=0에서 미분이 불가능합니다. ReLU(x) = max(0, x)로 정의되며, x < 0일 때 0, x > 0일 때 x를 출력합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 163,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 55,
    "question": "[변형] SVM에서 커널 함수의 역할은?",
    "options": [
      "선형 분리 가능한 데이터만 처리한다",
      "비선형 데이터를 고차원 공간으로 매핑한다",
      "학습 속도를 향상시킨다",
      "메모리 사용량을 줄인다"
    ],
    "correct": 1,
    "explanation": "SVM의 커널 함수는 비선형 데이터를 고차원 특성 공간으로 매핑하여 선형 분리 가능하게 만드는 역할을 합니다. 대표적으로 RBF, 다항식, 시그모이드 커널이 있습니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 164,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 56,
    "question": "[변형] 연관규칙에서 지지도(Support)의 정의는?",
    "options": [
      "P(A∩B)/P(A)",
      "P(A∩B)",
      "P(A∩B)/P(B)",
      "P(A)×P(B)"
    ],
    "correct": 1,
    "explanation": "지지도(Support)는 P(A∩B)로 정의됩니다. 신뢰도(Confidence)는 P(B|A) = P(A∩B)/P(A), 향상도(Lift)는 P(B|A)/P(B)입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 165,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 모델링",
    "question_number": 57,
    "question": "[변형] K-Means 클러스터링에서 K를 결정하는 방법으로 적절한 것은?",
    "options": [
      "실루엣 분석",
      "엘보우 방법",
      "WCSS 분석",
      "모두 맞다"
    ],
    "correct": 3,
    "explanation": "K-Means에서 최적의 K를 결정하는 방법에는 엘보우 방법(Elbow Method), 실루엣 분석(Silhouette Analysis), WCSS 분석 등이 모두 사용됩니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 166,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 결과해석",
    "question_number": 58,
    "question": "[변형] AUC 값이 0.5에 가까울 때의 의미는?",
    "options": [
      "완벽한 분류기",
      "매우 좋은 분류기",
      "무작위 분류기 수준",
      "최악의 분류기"
    ],
    "correct": 2,
    "explanation": "AUC(Area Under the Curve) 값이 0.5는 무작위 분류기 수준을 의미합니다. 1에 가까울수록 좋은 분류기, 0.8~0.9면 우수한 분류기로 평가합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 167,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 결과해석",
    "question_number": 59,
    "question": "[변형] 회귀 모델의 평가지표 중 RMSE는 무엇의 약자인가?",
    "options": [
      "Root Mean Square Error",
      "Relative Mean Square Error",
      "Random Mean Square Error",
      "Robust Mean Square Error"
    ],
    "correct": 0,
    "explanation": "RMSE는 Root Mean Square Error(평균제곱근오차)의 약자입니다. MSE에 제곱근을 취한 값으로, 실제값과 예측값의 차이를 나타냅니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 168,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 결과해석",
    "question_number": 60,
    "question": "[변형] 실루엣 계수(Silhouette Coefficient)의 범위는?",
    "options": [
      "[0, 1]",
      "[-1, 1]",
      "[0, ∞]",
      "[-∞, ∞]"
    ],
    "correct": 1,
    "explanation": "실루엣 계수는 -1과 1 사이의 값을 가집니다. 1에 가까우면 잘 분류됨, 0에 가까우면 경계에 있음, -1에 가까우면 잘못 분류됨을 의미합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 169,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 결과해석",
    "question_number": 61,
    "question": "[변형] K-Fold 교차검증에서 K=5일 때 훈련 데이터의 비율은?",
    "options": [
      "20%",
      "40%",
      "60%",
      "80%"
    ],
    "correct": 3,
    "explanation": "K-Fold 교차검증에서 K=5이면 데이터를 5등분하여 1개를 검증용(20%), 4개를 훈련용(80%)으로 사용합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 170,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 결과해석",
    "question_number": 62,
    "question": "[변형] 과적합(Overfitting)을 방지하는 방법이 아닌 것은?",
    "options": [
      "Dropout",
      "L2 Regularization",
      "더 복잡한 모델 사용",
      "Early Stopping"
    ],
    "correct": 2,
    "explanation": "과적합 방지 방법에는 Dropout, 정규화(L1/L2), Early Stopping, 데이터 증강 등이 있습니다. 더 복잡한 모델을 사용하면 과적합이 더 심해집니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 171,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 결과해석",
    "question_number": 63,
    "question": "[변형] GridSearchCV의 목적은?",
    "options": [
      "과적합을 방지한다",
      "하이퍼파라미터를 최적화한다",
      "특성을 선택한다",
      "데이터를 전처리한다"
    ],
    "correct": 1,
    "explanation": "GridSearchCV는 하이퍼파라미터의 최적 조합을 찾기 위해 격자 탐색(Grid Search)과 교차검증을 결합한 방법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 172,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 결과해석",
    "question_number": 64,
    "question": "[변형] 시각화에서 산점도(Scatter Plot)가 가장 적합한 용도는?",
    "options": [
      "범주별 빈도 비교",
      "두 연속형 변수의 상관관계",
      "시간에 따른 변화",
      "분포의 형태"
    ],
    "correct": 1,
    "explanation": "산점도는 두 연속형 변수 간의 상관관계나 패턴을 시각화하는 데 가장 적합합니다. 막대그래프는 범주별 비교, 선그래프는 시간 변화, 히스토그램은 분포 형태에 적합합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 173,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 결과해석",
    "question_number": 65,
    "question": "[변형] Confusion Matrix에서 Type I Error는?",
    "options": [
      "True Positive",
      "True Negative",
      "False Positive",
      "False Negative"
    ],
    "correct": 2,
    "explanation": "Type I Error는 False Positive(FP)로, 실제로는 음성인데 양성으로 잘못 분류한 경우입니다. Type II Error는 False Negative(FN)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 174,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 결과해석",
    "question_number": 66,
    "question": "[변형] Bootstrap 샘플링에서 Out-of-Bag 비율은 약 얼마인가?",
    "options": [
      "36.8%",
      "50%",
      "63.2%",
      "70%"
    ],
    "correct": 0,
    "explanation": "Bootstrap 샘플링에서 복원추출로 인해 선택되지 않을 확률은 약 36.8%입니다. 이를 Out-of-Bag(OOB) 샘플이라고 합니다.",
    "difficulty": "★★★★★",
    "difficulty_level": 5
  },
  {
    "id": 175,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 결과해석",
    "question_number": 67,
    "question": "[변형] L2 정규화(Ridge)에서 람다(λ) 값이 클수록?",
    "options": [
      "과적합이 증가한다",
      "모델 복잡도가 증가한다",
      "가중치 감소 효과가 커진다",
      "정확도가 항상 향상된다"
    ],
    "correct": 2,
    "explanation": "L2 정규화에서 λ 값이 클수록 가중치를 더 많이 감소시켜 모델을 단순하게 만들고 과적합을 방지합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 176,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 결과해석",
    "question_number": 68,
    "question": "[변형] Adjusted R-squared가 R-squared보다 낮은 이유는?",
    "options": [
      "계산 오류",
      "독립변수 개수에 대한 페널티",
      "종속변수의 영향",
      "표본 크기의 영향"
    ],
    "correct": 1,
    "explanation": "Adjusted R-squared는 독립변수의 개수가 증가할 때 발생하는 R-squared의 과대추정을 보정하기 위해 독립변수 개수에 대한 페널티를 부과합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 177,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 결과해석",
    "question_number": 69,
    "question": "[변형] 엘보우 방법(Elbow Method)이 사용되는 목적은?",
    "options": [
      "최적의 학습률 찾기",
      "최적의 클러스터 수 결정",
      "특성 선택",
      "모델 성능 평가"
    ],
    "correct": 1,
    "explanation": "엘보우 방법은 K-Means 클러스터링에서 최적의 클러스터 수(K)를 결정하기 위해 WCSS(Within-Cluster Sum of Squares)의 변화를 관찰하는 방법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 178,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 결과해석",
    "question_number": 70,
    "question": "[변형] 혼동행렬에서 Precision(정밀도)을 구하는 공식은?",
    "options": [
      "TP / (TP + FN)",
      "TP / (TP + FP)",
      "TN / (TN + FP)",
      "TN / (TN + FN)"
    ],
    "correct": 1,
    "explanation": "정밀도(Precision) = TP / (TP + FP)입니다. 예측한 양성 중에서 실제 양성인 비율을 의미합니다. 재현율(Recall) = TP / (TP + FN)입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 179,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 결과해석",
    "question_number": 71,
    "question": "[변형] F1-score는 다음 중 어떤 두 지표의 조화평균인가?",
    "options": [
      "Accuracy와 Precision",
      "Precision과 Recall",
      "Recall과 Specificity",
      "Accuracy와 Recall"
    ],
    "correct": 1,
    "explanation": "F1-score는 정밀도(Precision)와 재현율(Recall)의 조화평균입니다. F1 = 2 × (Precision × Recall) / (Precision + Recall)",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 180,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 결과해석",
    "question_number": 72,
    "question": "[변형] ROC 곡선의 x축과 y축은?",
    "options": [
      "FPR, TPR",
      "TPR, FPR",
      "Precision, Recall",
      "Accuracy, F1-score"
    ],
    "correct": 0,
    "explanation": "ROC 곡선의 x축은 FPR(False Positive Rate), y축은 TPR(True Positive Rate)입니다. FPR = FP/(FP+TN), TPR = TP/(TP+FN)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 181,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 결과해석",
    "question_number": 73,
    "question": "[변형] AUC 값이 0.5에 가까울 때의 의미는?",
    "options": [
      "완벽한 분류기",
      "매우 좋은 분류기",
      "무작위 분류기 수준",
      "최악의 분류기"
    ],
    "correct": 2,
    "explanation": "AUC(Area Under the Curve) 값이 0.5는 무작위 분류기 수준을 의미합니다. 1에 가까울수록 좋은 분류기, 0.8~0.9면 우수한 분류기로 평가합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 182,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 결과해석",
    "question_number": 74,
    "question": "[변형] 회귀 모델의 평가지표 중 RMSE는 무엇의 약자인가?",
    "options": [
      "Root Mean Square Error",
      "Relative Mean Square Error",
      "Random Mean Square Error",
      "Robust Mean Square Error"
    ],
    "correct": 0,
    "explanation": "RMSE는 Root Mean Square Error(평균제곱근오차)의 약자입니다. MSE에 제곱근을 취한 값으로, 실제값과 예측값의 차이를 나타냅니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 183,
    "type": "예상문제",
    "round": "2회차",
    "section": "빅데이터 결과해석",
    "question_number": 75,
    "question": "[변형] 실루엣 계수(Silhouette Coefficient)의 범위는?",
    "options": [
      "[0, 1]",
      "[-1, 1]",
      "[0, ∞]",
      "[-∞, ∞]"
    ],
    "correct": 1,
    "explanation": "실루엣 계수는 -1과 1 사이의 값을 가집니다. 1에 가까우면 잘 분류됨, 0에 가까우면 경계에 있음, -1에 가까우면 잘못 분류됨을 의미합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 184,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 1,
    "question": "[변형] STEEP 분석에서 'E'가 두 번 나오는데, 이 두 'E'가 의미하는 것은?",
    "options": [
      "Economic, Environmental",
      "Educational, Ethical",
      "Electronic, Emotional",
      "Efficient, Effective"
    ],
    "correct": 0,
    "explanation": "STEEP 분석은 Social(사회적), Technological(기술적), Economic(경제적), Environmental(환경적), Political(정치적) 요인을 분석하는 기법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 185,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 2,
    "question": "[변형] 데이터 품질 검증 항목이 아닌 것은?",
    "options": [
      "완전성(Completeness)",
      "정확성(Accuracy)",
      "일관성(Consistency)",
      "확장성(Scalability)"
    ],
    "correct": 3,
    "explanation": "데이터 품질 검증 항목에는 완전성, 정확성, 일관성, 유효성, 유일성 등이 있습니다. 확장성은 시스템 성능과 관련된 항목입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 186,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 3,
    "question": "[변형] 스키마 온 라이트(Schema on Write)와 스키마 온 리드(Schema on Read)에 대한 설명으로 옳은 것은?",
    "options": [
      "둘 다 동일한 개념이다",
      "스키마 온 라이트는 NoSQL에서 주로 사용된다",
      "스키마 온 리드는 RDBMS에서 주로 사용된다",
      "스키마 온 리드는 데이터를 읽을 때 스키마를 정의한다"
    ],
    "correct": 3,
    "explanation": "스키마 온 라이트는 데이터를 저장할 때 스키마를 정의하는 방식(RDBMS)이고, 스키마 온 리드는 데이터를 읽을 때 스키마를 정의하는 방식(NoSQL, 빅데이터)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 187,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 4,
    "question": "[변형] 클라우드 컴퓨팅의 서비스 모델 중 PaaS는 무엇의 약자인가?",
    "options": [
      "Platform as a Service",
      "Program as a Service",
      "Process as a Service",
      "Performance as a Service"
    ],
    "correct": 0,
    "explanation": "클라우드 컴퓨팅의 서비스 모델은 IaaS(Infrastructure as a Service), PaaS(Platform as a Service), SaaS(Software as a Service)가 있습니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 188,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 5,
    "question": "[변형] 빅데이터의 5V 중 '신뢰성'을 의미하는 것은?",
    "options": [
      "Volume",
      "Velocity",
      "Variety",
      "Veracity"
    ],
    "correct": 3,
    "explanation": "빅데이터의 5V는 Volume(규모), Velocity(속도), Variety(다양성), Value(가치), Veracity(신뢰성)입니다. Veracity는 데이터의 정확성과 신뢰성을 의미합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 189,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 6,
    "question": "[변형] DIKW 피라미드에서 가장 상위 단계는?",
    "options": [
      "Data",
      "Information",
      "Knowledge",
      "Wisdom"
    ],
    "correct": 3,
    "explanation": "DIKW 피라미드는 Data → Information → Knowledge → Wisdom 순으로 구성되며, Wisdom(지혜)이 가장 상위 단계입니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 190,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 7,
    "question": "[변형] SECI 모델에서 형식지를 암묵지로 변환하는 과정은?",
    "options": [
      "공통화(Socialization)",
      "표출화(Externalization)",
      "연결화(Combination)",
      "내면화(Internalization)"
    ],
    "correct": 3,
    "explanation": "SECI 모델에서 내면화(Internalization)는 형식지를 암묵지로 변환하는 과정입니다. 공통화는 암묵지→암묵지, 표출화는 암묵지→형식지, 연결화는 형식지→형식지입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 191,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 8,
    "question": "[변형] NoSQL DBMS의 특징으로 옳지 않은 것은?",
    "options": [
      "비정형 데이터 저장 및 관리에 적합하다",
      "형식에 얽매이지 않는다",
      "테이블 형태로 데이터를 정리한다",
      "인스타그램, 유튜브 등에서 사용한다"
    ],
    "correct": 2,
    "explanation": "NoSQL DBMS는 비정형 데이터 저장에 적합하고 형식에 얽매이지 않는 특징이 있습니다. 테이블 형태로 데이터를 정리하는 것은 관계형 DBMS(RDBMS)의 특징입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 192,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 9,
    "question": "[변형] 데이터베이스의 특징을 나타내는 '공통 저변'에서 '저'가 의미하는 것은?",
    "options": [
      "공용 데이터",
      "통합된 데이터",
      "저장된 데이터",
      "변화되는 데이터"
    ],
    "correct": 2,
    "explanation": "데이터베이스의 특징 '공통 저변'은 공용 데이터, 통합된 데이터, 저장된 데이터, 변화되는 데이터를 의미합니다. '저'는 저장된 데이터를 나타냅니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 193,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 10,
    "question": "[변형] 빅데이터 활용을 위한 3대 요소는?",
    "options": [
      "인력, 자원, 기술",
      "수집, 저장, 분석",
      "정형, 반정형, 비정형",
      "Volume, Velocity, Variety"
    ],
    "correct": 0,
    "explanation": "빅데이터 활용을 위한 3대 요소는 인력(분석 전문가), 자원(데이터 및 하드웨어), 기술(분석 기술 및 도구)입니다. 암기 팁으로 '인자기'를 사용할 수 있습니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 194,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 11,
    "question": "[변형] OLTP에 대한 설명으로 옳은 것은?",
    "options": [
      "대화식 분석 처리",
      "거래 단위 트랜잭션 처리",
      "고객 관계 관리",
      "공급망 관리"
    ],
    "correct": 1,
    "explanation": "OLTP(Online Transaction Processing)는 거래 단위 트랜잭션 처리를 의미합니다. OLAP는 대화식 분석 처리, CRM은 고객 관계 관리, SCM은 공급망 관리입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 195,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 12,
    "question": "[변형] 메타데이터(Metadata)에 대한 설명으로 옳은 것은?",
    "options": [
      "데이터를 설명하기 위한 데이터",
      "데이터의 타입과 값을 정의",
      "DB에 대한 전반적인 명세",
      "정렬 탐색을 위한 데이터의 이름"
    ],
    "correct": 0,
    "explanation": "메타데이터(Metadata)는 데이터를 설명하기 위한 데이터입니다. 인스턴스는 데이터 타입과 값을 정의, 스키마는 DB에 대한 전반적인 명세, 인덱스는 정렬 탐색을 위한 데이터의 이름입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 196,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 13,
    "question": "[변형] 개인정보 비식별화 기법이 아닌 것은?",
    "options": [
      "가명 처리",
      "총계 처리",
      "데이터 마스킹",
      "데이터 암호화"
    ],
    "correct": 3,
    "explanation": "개인정보 비식별화 기법에는 가명처리, 총계처리, 데이터 마스킹, 특이화(일반화), 범주화 등이 있습니다. 데이터 암호화는 개인정보 보호 기법이지만 비식별화 기법은 아닙니다.",
    "difficulty": "★★★★★",
    "difficulty_level": 5
  },
  {
    "id": 197,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 14,
    "question": "[변형] MyData의 3대 원칙은?",
    "options": [
      "수집, 저장, 활용",
      "개인 주도, 시장 주도, 정부 지원",
      "정형, 반정형, 비정형",
      "수집, 전송, 활용"
    ],
    "correct": 1,
    "explanation": "MyData의 3대 원칙은 개인 주도(개인이 본인 데이터 활용 직접 결정), 시장 주도(민간이 주도하는 데이터 경제), 정부 지원(제도·기술적 기반 마련)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 198,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 15,
    "question": "[변형] 하둡(Hadoop) HDFS의 특징으로 옳지 않은 것은?",
    "options": [
      "분산 저장이 가능하다",
      "높은 내결함성을 제공한다",
      "단일 장애점이 존재한다",
      "대용량 데이터 처리에 최적화되어 있다"
    ],
    "correct": 2,
    "explanation": "하둡 HDFS는 분산 저장, 높은 내결함성, 대용량 데이터 처리에 최적화된 특징이 있습니다. 단일 장애점(Single Point of Failure)을 해결하는 것이 HDFS의 주요 목적 중 하나입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 199,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 16,
    "question": "[변형] 데이터 웨어하우스(Data Warehouse)의 특징이 아닌 것은?",
    "options": [
      "주제 지향적(Subject-Oriented)",
      "통합적(Integrated)",
      "시간 변동적(Time-Variant)",
      "실시간 처리(Real-time Processing)"
    ],
    "correct": 3,
    "explanation": "데이터 웨어하우스의 특징은 주제 지향적, 통합적, 시간 변동적, 비휘발적(Non-Volatile)입니다. 실시간 처리보다는 배치 처리에 최적화되어 있습니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 200,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 17,
    "question": "[변형] ETL 프로세스에서 'T'가 의미하는 것은?",
    "options": [
      "Transfer",
      "Transform",
      "Transmit",
      "Transpose"
    ],
    "correct": 1,
    "explanation": "ETL은 Extraction(추출), Transformation(변환), Loading(적재)의 약자입니다. 'T'는 Transform(변환)을 의미합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 201,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 18,
    "question": "[변형] CRISP-DM 방법론의 6단계 중 첫 번째 단계는?",
    "options": [
      "데이터 이해",
      "비즈니스 이해",
      "데이터 준비",
      "모델링"
    ],
    "correct": 1,
    "explanation": "CRISP-DM 방법론의 6단계는 ①비즈니스 이해 ②데이터 이해 ③데이터 준비 ④모델링 ⑤평가 ⑥배포 순서입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 202,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 개론",
    "question_number": 19,
    "question": "[변형] KDD(Knowledge Discovery in Databases) 프로세스에서 첫 번째 단계는?",
    "options": [
      "Selection",
      "Preprocessing",
      "Transformation",
      "Data Mining"
    ],
    "correct": 0,
    "explanation": "KDD 프로세스는 ①선택(Selection) ②전처리(Preprocessing) ③변환(Transformation) ④데이터마이닝(Data Mining) ⑤해석/평가(Interpretation/Evaluation) 순서입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 203,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 20,
    "question": "[변형] 불균형 데이터 처리 방법이 아닌 것은?",
    "options": [
      "Under-sampling",
      "Over-sampling",
      "Weight Balancing",
      "Data Normalization"
    ],
    "correct": 3,
    "explanation": "불균형 데이터 처리 방법에는 Under-sampling(다수 클래스 축소), Over-sampling(소수 클래스 확대), Weight Balancing(가중치 조정) 등이 있습니다. Data Normalization은 스케일링 기법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 204,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 21,
    "question": "[변형] SMOTE 기법에 대한 설명으로 옳은 것은?",
    "options": [
      "Under-sampling 기법이다",
      "Over-sampling 기법이다",
      "정규화 기법이다",
      "차원축소 기법이다"
    ],
    "correct": 1,
    "explanation": "SMOTE(Synthetic Minority Oversampling Technique)는 소수 클래스의 합성 데이터를 생성하여 데이터 불균형을 해결하는 Over-sampling 기법입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 205,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 22,
    "question": "[변형] t-검정에서 사용하는 분포는?",
    "options": [
      "정규분포",
      "t-분포",
      "카이제곱분포",
      "F-분포"
    ],
    "correct": 1,
    "explanation": "t-검정은 모표준편차를 모를 때 사용하며, t-분포를 따릅니다. 표본 크기가 클수록 정규분포에 근사합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 206,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 23,
    "question": "[변형] 다중공선성(Multicollinearity) 진단 지표로 사용되는 것은?",
    "options": [
      "R-squared",
      "VIF",
      "AIC",
      "MSE"
    ],
    "correct": 1,
    "explanation": "VIF(Variance Inflation Factor)는 다중공선성을 진단하는 지표입니다. 일반적으로 VIF > 10이면 심각한 다중공선성이 있다고 판단합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 207,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 24,
    "question": "[변형] 결측값 처리 방법 중 MCAR은 무엇의 약자인가?",
    "options": [
      "Missing Completely At Random",
      "Missing Conditionally At Random",
      "Missing Constantly At Random",
      "Missing Correctly At Random"
    ],
    "correct": 0,
    "explanation": "MCAR은 Missing Completely At Random의 약자로, 결측값이 완전히 무작위로 발생한 경우를 의미합니다. MAR(Missing At Random), MNAR(Missing Not At Random)과 구별됩니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 208,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 25,
    "question": "[변형] 이상값 탐지 방법 중 IQR을 이용한 방법에서 이상값의 기준은?",
    "options": [
      "Q1 - 1.0×IQR 미만, Q3 + 1.0×IQR 초과",
      "Q1 - 1.5×IQR 미만, Q3 + 1.5×IQR 초과",
      "Q1 - 2.0×IQR 미만, Q3 + 2.0×IQR 초과",
      "Q1 - 3.0×IQR 미만, Q3 + 3.0×IQR 초과"
    ],
    "correct": 1,
    "explanation": "IQR(Inter Quartile Range) 방법에서는 Q1 - 1.5×IQR 미만이거나 Q3 + 1.5×IQR 초과하는 값을 이상값으로 판단합니다. IQR = Q3 - Q1입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 209,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 26,
    "question": "[변형] Z-score 정규화 공식에서 분모에 해당하는 것은?",
    "options": [
      "평균",
      "최댓값",
      "표준편차",
      "중앙값"
    ],
    "correct": 2,
    "explanation": "Z-score 정규화는 Z = (X - μ)/σ 공식을 사용합니다. 여기서 μ는 평균, σ는 표준편차입니다. 표준편차가 분모에 해당합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 210,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 27,
    "question": "[변형] Min-Max 정규화의 결과 범위는?",
    "options": [
      "[-1, 1]",
      "[0, 1]",
      "[-∞, ∞]",
      "[0, 100]"
    ],
    "correct": 1,
    "explanation": "Min-Max 정규화는 데이터를 0과 1 사이의 값으로 변환하는 방법입니다. 공식: (X - min)/(max - min)",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 211,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 28,
    "question": "[변형] 원-핫 인코딩(One-Hot Encoding)에 대한 설명으로 옳은 것은?",
    "options": [
      "수치형 데이터를 범주형으로 변환한다",
      "범주형 데이터를 0과 1로 이루어진 벡터로 변환한다",
      "연속형 데이터를 구간별로 나눈다",
      "결측값을 평균으로 대체한다"
    ],
    "correct": 1,
    "explanation": "원-핫 인코딩은 범주형 데이터를 0과 1로 이루어진 벡터로 변환하는 방법입니다. 각 범주마다 새로운 이진 변수를 생성합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 212,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 29,
    "question": "[변형] PCA(주성분 분석)의 목적은?",
    "options": [
      "데이터 양을 증가시킨다",
      "차원을 축소한다",
      "결측값을 처리한다",
      "이상값을 제거한다"
    ],
    "correct": 1,
    "explanation": "PCA(Principal Component Analysis)는 고차원 데이터를 저차원으로 축소하여 차원의 저주를 해결하고 계산 효율성을 높이는 기법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 213,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 30,
    "question": "[변형] 피어슨 상관계수의 범위는?",
    "options": [
      "[0, 1]",
      "[-1, 1]",
      "[0, ∞]",
      "[-∞, ∞]"
    ],
    "correct": 1,
    "explanation": "피어슨 상관계수는 -1과 1 사이의 값을 가집니다. -1에 가까우면 강한 음의 상관관계, 1에 가까우면 강한 양의 상관관계, 0에 가까우면 상관관계가 없음을 의미합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 214,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 31,
    "question": "[변형] 첨도(Kurtosis)가 3보다 클 때 분포의 특징은?",
    "options": [
      "평평한 분포",
      "뾰족한 분포",
      "치우친 분포",
      "정규 분포"
    ],
    "correct": 1,
    "explanation": "첨도가 3보다 크면 뾰족한 분포(leptokurtic), 3보다 작으면 평평한 분포(platykurtic), 3이면 정규분포(mesokurtic)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 215,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 32,
    "question": "[변형] 왜도(Skewness)가 0보다 클 때 분포의 특징은?",
    "options": [
      "좌편향 분포",
      "우편향 분포",
      "정규 분포",
      "이봉 분포"
    ],
    "correct": 1,
    "explanation": "왜도가 0보다 크면 우편향(right-skewed) 분포, 0보다 작으면 좌편향(left-skewed) 분포, 0이면 대칭 분포입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 216,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 33,
    "question": "[변형] 중심극한정리에서 표본 크기가 얼마 이상일 때 정규분포에 근사한다고 보는가?",
    "options": [
      "20",
      "30",
      "50",
      "100"
    ],
    "correct": 1,
    "explanation": "중심극한정리에 의하면 표본 크기가 30 이상일 때 표본평균의 분포가 정규분포에 근사한다고 봅니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 217,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 34,
    "question": "[변형] 표준오차(Standard Error)를 구하는 공식에서 분모는?",
    "options": [
      "표본 크기",
      "표본 크기의 제곱근",
      "표준편차",
      "분산"
    ],
    "correct": 1,
    "explanation": "표준오차 = σ/√n (σ: 모표준편차, n: 표본크기) 또는 s/√n (s: 표본표준편차)입니다. 분모는 표본 크기의 제곱근입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 218,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 35,
    "question": "[변형] 95% 신뢰구간에서 사용하는 Z값은?",
    "options": [
      "1.64",
      "1.96",
      "2.33",
      "2.58"
    ],
    "correct": 1,
    "explanation": "95% 신뢰구간에서는 α=0.05이므로 α/2=0.025입니다. 따라서 Z_{0.025} = 1.96을 사용합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 219,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 36,
    "question": "[변형] 가설검정에서 1종 오류(Type I Error)는?",
    "options": [
      "귀무가설이 참인데 귀무가설을 기각하는 오류",
      "귀무가설이 거짓인데 귀무가설을 채택하는 오류",
      "대립가설이 참인데 대립가설을 기각하는 오류",
      "대립가설이 거짓인데 대립가설을 채택하는 오류"
    ],
    "correct": 0,
    "explanation": "1종 오류(Type I Error)는 귀무가설이 참인데 이를 기각하는 오류입니다. 2종 오류(Type II Error)는 귀무가설이 거짓인데 이를 채택하는 오류입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 220,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 37,
    "question": "[변형] 층화표집(Stratified Sampling)에 대한 설명으로 옳은 것은?",
    "options": [
      "모집단을 동질적인 계층으로 나누어 각 계층에서 표본을 추출한다",
      "모집단을 지역별로 나누어 일부 지역을 선택한다",
      "체계적으로 일정한 간격으로 표본을 추출한다",
      "완전히 무작위로 표본을 추출한다"
    ],
    "correct": 0,
    "explanation": "층화표집은 모집단을 특성이 비슷한 몇 개의 계층(strata)으로 나눈 후, 각 계층에서 표본을 추출하는 방법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 221,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 기획",
    "question_number": 38,
    "question": "[변형] 베이즈 정리에서 P(A|B) × P(B) = ?",
    "options": [
      "P(B|A)",
      "P(A∩B)",
      "P(A∪B)",
      "P(A) × P(B)"
    ],
    "correct": 1,
    "explanation": "베이즈 정리: P(A|B) = P(B|A) × P(A) / P(B)에서 P(A|B) × P(B) = P(B|A) × P(A) = P(A∩B)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 222,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 39,
    "question": "[변형] K-Means 클러스터링에서 K를 결정하는 방법으로 적절한 것은?",
    "options": [
      "실루엣 분석",
      "엘보우 방법",
      "WCSS 분석",
      "모두 맞다"
    ],
    "correct": 3,
    "explanation": "K-Means에서 최적의 K를 결정하는 방법에는 엘보우 방법(Elbow Method), 실루엣 분석(Silhouette Analysis), WCSS 분석 등이 모두 사용됩니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 223,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 40,
    "question": "[변형] DBSCAN 클러스터링의 매개변수가 아닌 것은?",
    "options": [
      "eps (반경)",
      "min_samples (최소 점의 수)",
      "k (클러스터 수)",
      "metric (거리 측정법)"
    ],
    "correct": 2,
    "explanation": "DBSCAN의 주요 매개변수는 eps(이웃을 정의하는 반경), min_samples(핵심점이 되기 위한 최소 이웃 수)입니다. K-Means와 달리 클러스터 수를 미리 정하지 않습니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 224,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 41,
    "question": "[변형] 시계열 분석에서 정상성(Stationarity)의 조건이 아닌 것은?",
    "options": [
      "평균이 시간에 무관하게 일정하다",
      "분산이 시간에 무관하게 일정하다",
      "자기공분산이 시차에만 의존한다",
      "추세가 지속적으로 증가한다"
    ],
    "correct": 3,
    "explanation": "정상성(Stationarity)의 조건은 ①평균이 시간에 무관하게 일정 ②분산이 시간에 무관하게 일정 ③자기공분산이 시차에만 의존입니다. 추세가 있으면 비정상 시계열입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 225,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 42,
    "question": "[변형] ARIMA(p,d,q) 모델에서 'd'가 의미하는 것은?",
    "options": [
      "자기회귀 차수",
      "이동평균 차수",
      "차분 차수",
      "계절성 차수"
    ],
    "correct": 2,
    "explanation": "ARIMA(p,d,q)에서 p는 자기회귀(AR) 차수, d는 차분(Differencing) 차수, q는 이동평균(MA) 차수를 의미합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 226,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 43,
    "question": "[변형] 베이지안 분류에서 나이브(Naive)의 의미는?",
    "options": [
      "단순함",
      "독립성 가정",
      "확률적",
      "조건부"
    ],
    "correct": 1,
    "explanation": "나이브 베이즈에서 '나이브(Naive)'는 모든 특성들이 서로 독립이라고 가정하는 것을 의미합니다. 이는 현실적이지 않은 가정이지만 계산을 단순화합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 227,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 44,
    "question": "[변형] CNN에서 컨볼루션 연산의 목적은?",
    "options": [
      "차원을 축소한다",
      "지역적 특징을 추출한다",
      "과적합을 방지한다",
      "계산량을 줄인다"
    ],
    "correct": 1,
    "explanation": "CNN의 컨볼루션 연산은 필터(커널)를 사용하여 입력 데이터의 지역적 특징(local features)을 추출하는 역할을 합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 228,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 45,
    "question": "[변형] RNN에서 장기 의존성 문제를 해결하는 모델은?",
    "options": [
      "LSTM",
      "CNN",
      "SVM",
      "Decision Tree"
    ],
    "correct": 0,
    "explanation": "LSTM(Long Short-Term Memory)은 RNN의 장기 의존성 문제와 기울기 소실 문제를 해결하기 위해 개발된 모델입니다. GRU도 유사한 목적으로 사용됩니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 229,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 46,
    "question": "[변형] 랜덤 포레스트의 특징으로 옳지 않은 것은?",
    "options": [
      "배깅(Bagging) 기법을 사용한다",
      "여러 의사결정나무를 결합한다",
      "과적합에 강하다",
      "선형 모델이다"
    ],
    "correct": 3,
    "explanation": "랜덤 포레스트는 배깅을 사용한 앙상블 모델로, 여러 의사결정나무를 결합하여 과적합에 강한 특징이 있습니다. 비선형 모델입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 230,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 47,
    "question": "[변형] 부스팅(Boosting) 앙상블의 특징은?",
    "options": [
      "모델을 독립적으로 학습한다",
      "순차적으로 학습하여 오류를 보완한다",
      "모든 모델에 동일한 가중치를 부여한다",
      "배깅과 동일한 방법이다"
    ],
    "correct": 1,
    "explanation": "부스팅은 모델을 순차적으로 학습하면서 이전 모델의 오류를 다음 모델이 보완하도록 하는 앙상블 기법입니다. 대표적으로 AdaBoost, Gradient Boosting이 있습니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 231,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 48,
    "question": "[변형] 회귀분석에서 R-squared가 의미하는 것은?",
    "options": [
      "오차의 제곱합",
      "총변동에 대한 회귀변동의 비율",
      "독립변수의 개수",
      "표본의 크기"
    ],
    "correct": 1,
    "explanation": "R-squared(결정계수)는 총변동에 대한 회귀변동의 비율로, 독립변수가 종속변수의 변동을 얼마나 설명하는지를 나타냅니다. R² = SSR/SST",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 232,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 49,
    "question": "[변형] 로지스틱 회귀에서 사용하는 활성화 함수는?",
    "options": [
      "ReLU",
      "Sigmoid",
      "Tanh",
      "Linear"
    ],
    "correct": 1,
    "explanation": "로지스틱 회귀에서는 Sigmoid 함수를 사용하여 선형 조합을 0과 1 사이의 확률값으로 변환합니다. Sigmoid(z) = 1/(1+e^(-z))",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 233,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 50,
    "question": "[변형] 의사결정나무에서 과적합을 방지하는 방법이 아닌 것은?",
    "options": [
      "가지치기(Pruning)",
      "정지규칙(Stopping Rule)",
      "최대 깊이 제한",
      "학습률 조정"
    ],
    "correct": 3,
    "explanation": "의사결정나무에서 과적합 방지 방법에는 가지치기, 정지규칙, 최대 깊이 제한, 최소 분할 샘플 수 설정 등이 있습니다. 학습률 조정은 신경망에서 사용하는 방법입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 234,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 51,
    "question": "[변형] 신경망에서 ReLU 함수의 특징으로 옳지 않은 것은?",
    "options": [
      "계산이 간단하다",
      "기울기 소실 문제를 완화한다",
      "음수 입력에 대해 0을 출력한다",
      "모든 범위에서 미분 가능하다"
    ],
    "correct": 3,
    "explanation": "ReLU 함수는 x=0에서 미분이 불가능합니다. ReLU(x) = max(0, x)로 정의되며, x < 0일 때 0, x > 0일 때 x를 출력합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 235,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 52,
    "question": "[변형] SVM에서 커널 함수의 역할은?",
    "options": [
      "선형 분리 가능한 데이터만 처리한다",
      "비선형 데이터를 고차원 공간으로 매핑한다",
      "학습 속도를 향상시킨다",
      "메모리 사용량을 줄인다"
    ],
    "correct": 1,
    "explanation": "SVM의 커널 함수는 비선형 데이터를 고차원 특성 공간으로 매핑하여 선형 분리 가능하게 만드는 역할을 합니다. 대표적으로 RBF, 다항식, 시그모이드 커널이 있습니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 236,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 53,
    "question": "[변형] 연관규칙에서 지지도(Support)의 정의는?",
    "options": [
      "P(A∩B)/P(A)",
      "P(A∩B)",
      "P(A∩B)/P(B)",
      "P(A)×P(B)"
    ],
    "correct": 1,
    "explanation": "지지도(Support)는 P(A∩B)로 정의됩니다. 신뢰도(Confidence)는 P(B|A) = P(A∩B)/P(A), 향상도(Lift)는 P(B|A)/P(B)입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 237,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 54,
    "question": "[변형] K-Means 클러스터링에서 K를 결정하는 방법으로 적절한 것은?",
    "options": [
      "실루엣 분석",
      "엘보우 방법",
      "WCSS 분석",
      "모두 맞다"
    ],
    "correct": 3,
    "explanation": "K-Means에서 최적의 K를 결정하는 방법에는 엘보우 방법(Elbow Method), 실루엣 분석(Silhouette Analysis), WCSS 분석 등이 모두 사용됩니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 238,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 55,
    "question": "[변형] DBSCAN 클러스터링의 매개변수가 아닌 것은?",
    "options": [
      "eps (반경)",
      "min_samples (최소 점의 수)",
      "k (클러스터 수)",
      "metric (거리 측정법)"
    ],
    "correct": 2,
    "explanation": "DBSCAN의 주요 매개변수는 eps(이웃을 정의하는 반경), min_samples(핵심점이 되기 위한 최소 이웃 수)입니다. K-Means와 달리 클러스터 수를 미리 정하지 않습니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 239,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 56,
    "question": "[변형] 시계열 분석에서 정상성(Stationarity)의 조건이 아닌 것은?",
    "options": [
      "평균이 시간에 무관하게 일정하다",
      "분산이 시간에 무관하게 일정하다",
      "자기공분산이 시차에만 의존한다",
      "추세가 지속적으로 증가한다"
    ],
    "correct": 3,
    "explanation": "정상성(Stationarity)의 조건은 ①평균이 시간에 무관하게 일정 ②분산이 시간에 무관하게 일정 ③자기공분산이 시차에만 의존입니다. 추세가 있으면 비정상 시계열입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 240,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 모델링",
    "question_number": 57,
    "question": "[변형] ARIMA(p,d,q) 모델에서 'd'가 의미하는 것은?",
    "options": [
      "자기회귀 차수",
      "이동평균 차수",
      "차분 차수",
      "계절성 차수"
    ],
    "correct": 2,
    "explanation": "ARIMA(p,d,q)에서 p는 자기회귀(AR) 차수, d는 차분(Differencing) 차수, q는 이동평균(MA) 차수를 의미합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 241,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 결과해석",
    "question_number": 58,
    "question": "[변형] K-Fold 교차검증에서 K=5일 때 훈련 데이터의 비율은?",
    "options": [
      "20%",
      "40%",
      "60%",
      "80%"
    ],
    "correct": 3,
    "explanation": "K-Fold 교차검증에서 K=5이면 데이터를 5등분하여 1개를 검증용(20%), 4개를 훈련용(80%)으로 사용합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 242,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 결과해석",
    "question_number": 59,
    "question": "[변형] 과적합(Overfitting)을 방지하는 방법이 아닌 것은?",
    "options": [
      "Dropout",
      "L2 Regularization",
      "더 복잡한 모델 사용",
      "Early Stopping"
    ],
    "correct": 2,
    "explanation": "과적합 방지 방법에는 Dropout, 정규화(L1/L2), Early Stopping, 데이터 증강 등이 있습니다. 더 복잡한 모델을 사용하면 과적합이 더 심해집니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 243,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 결과해석",
    "question_number": 60,
    "question": "[변형] GridSearchCV의 목적은?",
    "options": [
      "과적합을 방지한다",
      "하이퍼파라미터를 최적화한다",
      "특성을 선택한다",
      "데이터를 전처리한다"
    ],
    "correct": 1,
    "explanation": "GridSearchCV는 하이퍼파라미터의 최적 조합을 찾기 위해 격자 탐색(Grid Search)과 교차검증을 결합한 방법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 244,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 결과해석",
    "question_number": 61,
    "question": "[변형] 시각화에서 산점도(Scatter Plot)가 가장 적합한 용도는?",
    "options": [
      "범주별 빈도 비교",
      "두 연속형 변수의 상관관계",
      "시간에 따른 변화",
      "분포의 형태"
    ],
    "correct": 1,
    "explanation": "산점도는 두 연속형 변수 간의 상관관계나 패턴을 시각화하는 데 가장 적합합니다. 막대그래프는 범주별 비교, 선그래프는 시간 변화, 히스토그램은 분포 형태에 적합합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 245,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 결과해석",
    "question_number": 62,
    "question": "[변형] Confusion Matrix에서 Type I Error는?",
    "options": [
      "True Positive",
      "True Negative",
      "False Positive",
      "False Negative"
    ],
    "correct": 2,
    "explanation": "Type I Error는 False Positive(FP)로, 실제로는 음성인데 양성으로 잘못 분류한 경우입니다. Type II Error는 False Negative(FN)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 246,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 결과해석",
    "question_number": 63,
    "question": "[변형] Bootstrap 샘플링에서 Out-of-Bag 비율은 약 얼마인가?",
    "options": [
      "36.8%",
      "50%",
      "63.2%",
      "70%"
    ],
    "correct": 0,
    "explanation": "Bootstrap 샘플링에서 복원추출로 인해 선택되지 않을 확률은 약 36.8%입니다. 이를 Out-of-Bag(OOB) 샘플이라고 합니다.",
    "difficulty": "★★★★★",
    "difficulty_level": 5
  },
  {
    "id": 247,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 결과해석",
    "question_number": 64,
    "question": "[변형] L2 정규화(Ridge)에서 람다(λ) 값이 클수록?",
    "options": [
      "과적합이 증가한다",
      "모델 복잡도가 증가한다",
      "가중치 감소 효과가 커진다",
      "정확도가 항상 향상된다"
    ],
    "correct": 2,
    "explanation": "L2 정규화에서 λ 값이 클수록 가중치를 더 많이 감소시켜 모델을 단순하게 만들고 과적합을 방지합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 248,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 결과해석",
    "question_number": 65,
    "question": "[변형] Adjusted R-squared가 R-squared보다 낮은 이유는?",
    "options": [
      "계산 오류",
      "독립변수 개수에 대한 페널티",
      "종속변수의 영향",
      "표본 크기의 영향"
    ],
    "correct": 1,
    "explanation": "Adjusted R-squared는 독립변수의 개수가 증가할 때 발생하는 R-squared의 과대추정을 보정하기 위해 독립변수 개수에 대한 페널티를 부과합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 249,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 결과해석",
    "question_number": 66,
    "question": "[변형] 엘보우 방법(Elbow Method)이 사용되는 목적은?",
    "options": [
      "최적의 학습률 찾기",
      "최적의 클러스터 수 결정",
      "특성 선택",
      "모델 성능 평가"
    ],
    "correct": 1,
    "explanation": "엘보우 방법은 K-Means 클러스터링에서 최적의 클러스터 수(K)를 결정하기 위해 WCSS(Within-Cluster Sum of Squares)의 변화를 관찰하는 방법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 250,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 결과해석",
    "question_number": 67,
    "question": "[변형] 혼동행렬에서 Precision(정밀도)을 구하는 공식은?",
    "options": [
      "TP / (TP + FN)",
      "TP / (TP + FP)",
      "TN / (TN + FP)",
      "TN / (TN + FN)"
    ],
    "correct": 1,
    "explanation": "정밀도(Precision) = TP / (TP + FP)입니다. 예측한 양성 중에서 실제 양성인 비율을 의미합니다. 재현율(Recall) = TP / (TP + FN)입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 251,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 결과해석",
    "question_number": 68,
    "question": "[변형] F1-score는 다음 중 어떤 두 지표의 조화평균인가?",
    "options": [
      "Accuracy와 Precision",
      "Precision과 Recall",
      "Recall과 Specificity",
      "Accuracy와 Recall"
    ],
    "correct": 1,
    "explanation": "F1-score는 정밀도(Precision)와 재현율(Recall)의 조화평균입니다. F1 = 2 × (Precision × Recall) / (Precision + Recall)",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 252,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 결과해석",
    "question_number": 69,
    "question": "[변형] ROC 곡선의 x축과 y축은?",
    "options": [
      "FPR, TPR",
      "TPR, FPR",
      "Precision, Recall",
      "Accuracy, F1-score"
    ],
    "correct": 0,
    "explanation": "ROC 곡선의 x축은 FPR(False Positive Rate), y축은 TPR(True Positive Rate)입니다. FPR = FP/(FP+TN), TPR = TP/(TP+FN)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 253,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 결과해석",
    "question_number": 70,
    "question": "[변형] AUC 값이 0.5에 가까울 때의 의미는?",
    "options": [
      "완벽한 분류기",
      "매우 좋은 분류기",
      "무작위 분류기 수준",
      "최악의 분류기"
    ],
    "correct": 2,
    "explanation": "AUC(Area Under the Curve) 값이 0.5는 무작위 분류기 수준을 의미합니다. 1에 가까울수록 좋은 분류기, 0.8~0.9면 우수한 분류기로 평가합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 254,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 결과해석",
    "question_number": 71,
    "question": "[변형] 회귀 모델의 평가지표 중 RMSE는 무엇의 약자인가?",
    "options": [
      "Root Mean Square Error",
      "Relative Mean Square Error",
      "Random Mean Square Error",
      "Robust Mean Square Error"
    ],
    "correct": 0,
    "explanation": "RMSE는 Root Mean Square Error(평균제곱근오차)의 약자입니다. MSE에 제곱근을 취한 값으로, 실제값과 예측값의 차이를 나타냅니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 255,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 결과해석",
    "question_number": 72,
    "question": "[변형] 실루엣 계수(Silhouette Coefficient)의 범위는?",
    "options": [
      "[0, 1]",
      "[-1, 1]",
      "[0, ∞]",
      "[-∞, ∞]"
    ],
    "correct": 1,
    "explanation": "실루엣 계수는 -1과 1 사이의 값을 가집니다. 1에 가까우면 잘 분류됨, 0에 가까우면 경계에 있음, -1에 가까우면 잘못 분류됨을 의미합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 256,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 결과해석",
    "question_number": 73,
    "question": "[변형] K-Fold 교차검증에서 K=5일 때 훈련 데이터의 비율은?",
    "options": [
      "20%",
      "40%",
      "60%",
      "80%"
    ],
    "correct": 3,
    "explanation": "K-Fold 교차검증에서 K=5이면 데이터를 5등분하여 1개를 검증용(20%), 4개를 훈련용(80%)으로 사용합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 257,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 결과해석",
    "question_number": 74,
    "question": "[변형] 과적합(Overfitting)을 방지하는 방법이 아닌 것은?",
    "options": [
      "Dropout",
      "L2 Regularization",
      "더 복잡한 모델 사용",
      "Early Stopping"
    ],
    "correct": 2,
    "explanation": "과적합 방지 방법에는 Dropout, 정규화(L1/L2), Early Stopping, 데이터 증강 등이 있습니다. 더 복잡한 모델을 사용하면 과적합이 더 심해집니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 258,
    "type": "예상문제",
    "round": "3회차",
    "section": "빅데이터 결과해석",
    "question_number": 75,
    "question": "[변형] GridSearchCV의 목적은?",
    "options": [
      "과적합을 방지한다",
      "하이퍼파라미터를 최적화한다",
      "특성을 선택한다",
      "데이터를 전처리한다"
    ],
    "correct": 1,
    "explanation": "GridSearchCV는 하이퍼파라미터의 최적 조합을 찾기 위해 격자 탐색(Grid Search)과 교차검증을 결합한 방법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 259,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 1,
    "question": "[변형] KDD(Knowledge Discovery in Databases) 프로세스에서 첫 번째 단계는?",
    "options": [
      "Selection",
      "Preprocessing",
      "Transformation",
      "Data Mining"
    ],
    "correct": 0,
    "explanation": "KDD 프로세스는 ①선택(Selection) ②전처리(Preprocessing) ③변환(Transformation) ④데이터마이닝(Data Mining) ⑤해석/평가(Interpretation/Evaluation) 순서입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 260,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 2,
    "question": "[변형] 빅데이터 분석 프로젝트에서 Problem Discovery 단계에 해당하지 않는 것은?",
    "options": [
      "What (무엇을)",
      "Why (왜)",
      "How (어떻게)",
      "When (언제)"
    ],
    "correct": 2,
    "explanation": "Problem Discovery 단계에서는 What(무엇을), Why(왜), When(언제)를 중점적으로 다룹니다. How(어떻게)는 Solution Search 단계에서 다루어집니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 261,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 3,
    "question": "[변형] STEEP 분석에서 'E'가 두 번 나오는데, 이 두 'E'가 의미하는 것은?",
    "options": [
      "Economic, Environmental",
      "Educational, Ethical",
      "Electronic, Emotional",
      "Efficient, Effective"
    ],
    "correct": 0,
    "explanation": "STEEP 분석은 Social(사회적), Technological(기술적), Economic(경제적), Environmental(환경적), Political(정치적) 요인을 분석하는 기법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 262,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 4,
    "question": "[변형] 데이터 품질 검증 항목이 아닌 것은?",
    "options": [
      "완전성(Completeness)",
      "정확성(Accuracy)",
      "일관성(Consistency)",
      "확장성(Scalability)"
    ],
    "correct": 3,
    "explanation": "데이터 품질 검증 항목에는 완전성, 정확성, 일관성, 유효성, 유일성 등이 있습니다. 확장성은 시스템 성능과 관련된 항목입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 263,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 5,
    "question": "[변형] 스키마 온 라이트(Schema on Write)와 스키마 온 리드(Schema on Read)에 대한 설명으로 옳은 것은?",
    "options": [
      "둘 다 동일한 개념이다",
      "스키마 온 라이트는 NoSQL에서 주로 사용된다",
      "스키마 온 리드는 RDBMS에서 주로 사용된다",
      "스키마 온 리드는 데이터를 읽을 때 스키마를 정의한다"
    ],
    "correct": 3,
    "explanation": "스키마 온 라이트는 데이터를 저장할 때 스키마를 정의하는 방식(RDBMS)이고, 스키마 온 리드는 데이터를 읽을 때 스키마를 정의하는 방식(NoSQL, 빅데이터)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 264,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 6,
    "question": "[변형] 클라우드 컴퓨팅의 서비스 모델 중 PaaS는 무엇의 약자인가?",
    "options": [
      "Platform as a Service",
      "Program as a Service",
      "Process as a Service",
      "Performance as a Service"
    ],
    "correct": 0,
    "explanation": "클라우드 컴퓨팅의 서비스 모델은 IaaS(Infrastructure as a Service), PaaS(Platform as a Service), SaaS(Software as a Service)가 있습니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 265,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 7,
    "question": "[변형] 빅데이터의 5V 중 '신뢰성'을 의미하는 것은?",
    "options": [
      "Volume",
      "Velocity",
      "Variety",
      "Veracity"
    ],
    "correct": 3,
    "explanation": "빅데이터의 5V는 Volume(규모), Velocity(속도), Variety(다양성), Value(가치), Veracity(신뢰성)입니다. Veracity는 데이터의 정확성과 신뢰성을 의미합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 266,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 8,
    "question": "[변형] DIKW 피라미드에서 가장 상위 단계는?",
    "options": [
      "Data",
      "Information",
      "Knowledge",
      "Wisdom"
    ],
    "correct": 3,
    "explanation": "DIKW 피라미드는 Data → Information → Knowledge → Wisdom 순으로 구성되며, Wisdom(지혜)이 가장 상위 단계입니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 267,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 9,
    "question": "[변형] SECI 모델에서 형식지를 암묵지로 변환하는 과정은?",
    "options": [
      "공통화(Socialization)",
      "표출화(Externalization)",
      "연결화(Combination)",
      "내면화(Internalization)"
    ],
    "correct": 3,
    "explanation": "SECI 모델에서 내면화(Internalization)는 형식지를 암묵지로 변환하는 과정입니다. 공통화는 암묵지→암묵지, 표출화는 암묵지→형식지, 연결화는 형식지→형식지입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 268,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 10,
    "question": "[변형] NoSQL DBMS의 특징으로 옳지 않은 것은?",
    "options": [
      "비정형 데이터 저장 및 관리에 적합하다",
      "형식에 얽매이지 않는다",
      "테이블 형태로 데이터를 정리한다",
      "인스타그램, 유튜브 등에서 사용한다"
    ],
    "correct": 2,
    "explanation": "NoSQL DBMS는 비정형 데이터 저장에 적합하고 형식에 얽매이지 않는 특징이 있습니다. 테이블 형태로 데이터를 정리하는 것은 관계형 DBMS(RDBMS)의 특징입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 269,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 11,
    "question": "[변형] 데이터베이스의 특징을 나타내는 '공통 저변'에서 '저'가 의미하는 것은?",
    "options": [
      "공용 데이터",
      "통합된 데이터",
      "저장된 데이터",
      "변화되는 데이터"
    ],
    "correct": 2,
    "explanation": "데이터베이스의 특징 '공통 저변'은 공용 데이터, 통합된 데이터, 저장된 데이터, 변화되는 데이터를 의미합니다. '저'는 저장된 데이터를 나타냅니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 270,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 12,
    "question": "[변형] 빅데이터 활용을 위한 3대 요소는?",
    "options": [
      "인력, 자원, 기술",
      "수집, 저장, 분석",
      "정형, 반정형, 비정형",
      "Volume, Velocity, Variety"
    ],
    "correct": 0,
    "explanation": "빅데이터 활용을 위한 3대 요소는 인력(분석 전문가), 자원(데이터 및 하드웨어), 기술(분석 기술 및 도구)입니다. 암기 팁으로 '인자기'를 사용할 수 있습니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 271,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 13,
    "question": "[변형] OLTP에 대한 설명으로 옳은 것은?",
    "options": [
      "대화식 분석 처리",
      "거래 단위 트랜잭션 처리",
      "고객 관계 관리",
      "공급망 관리"
    ],
    "correct": 1,
    "explanation": "OLTP(Online Transaction Processing)는 거래 단위 트랜잭션 처리를 의미합니다. OLAP는 대화식 분석 처리, CRM은 고객 관계 관리, SCM은 공급망 관리입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 272,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 14,
    "question": "[변형] 메타데이터(Metadata)에 대한 설명으로 옳은 것은?",
    "options": [
      "데이터를 설명하기 위한 데이터",
      "데이터의 타입과 값을 정의",
      "DB에 대한 전반적인 명세",
      "정렬 탐색을 위한 데이터의 이름"
    ],
    "correct": 0,
    "explanation": "메타데이터(Metadata)는 데이터를 설명하기 위한 데이터입니다. 인스턴스는 데이터 타입과 값을 정의, 스키마는 DB에 대한 전반적인 명세, 인덱스는 정렬 탐색을 위한 데이터의 이름입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 273,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 15,
    "question": "[변형] 개인정보 비식별화 기법이 아닌 것은?",
    "options": [
      "가명 처리",
      "총계 처리",
      "데이터 마스킹",
      "데이터 암호화"
    ],
    "correct": 3,
    "explanation": "개인정보 비식별화 기법에는 가명처리, 총계처리, 데이터 마스킹, 특이화(일반화), 범주화 등이 있습니다. 데이터 암호화는 개인정보 보호 기법이지만 비식별화 기법은 아닙니다.",
    "difficulty": "★★★★★",
    "difficulty_level": 5
  },
  {
    "id": 274,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 16,
    "question": "[변형] MyData의 3대 원칙은?",
    "options": [
      "수집, 저장, 활용",
      "개인 주도, 시장 주도, 정부 지원",
      "정형, 반정형, 비정형",
      "수집, 전송, 활용"
    ],
    "correct": 1,
    "explanation": "MyData의 3대 원칙은 개인 주도(개인이 본인 데이터 활용 직접 결정), 시장 주도(민간이 주도하는 데이터 경제), 정부 지원(제도·기술적 기반 마련)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 275,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 17,
    "question": "[변형] 하둡(Hadoop) HDFS의 특징으로 옳지 않은 것은?",
    "options": [
      "분산 저장이 가능하다",
      "높은 내결함성을 제공한다",
      "단일 장애점이 존재한다",
      "대용량 데이터 처리에 최적화되어 있다"
    ],
    "correct": 2,
    "explanation": "하둡 HDFS는 분산 저장, 높은 내결함성, 대용량 데이터 처리에 최적화된 특징이 있습니다. 단일 장애점(Single Point of Failure)을 해결하는 것이 HDFS의 주요 목적 중 하나입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 276,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 18,
    "question": "[변형] 데이터 웨어하우스(Data Warehouse)의 특징이 아닌 것은?",
    "options": [
      "주제 지향적(Subject-Oriented)",
      "통합적(Integrated)",
      "시간 변동적(Time-Variant)",
      "실시간 처리(Real-time Processing)"
    ],
    "correct": 3,
    "explanation": "데이터 웨어하우스의 특징은 주제 지향적, 통합적, 시간 변동적, 비휘발적(Non-Volatile)입니다. 실시간 처리보다는 배치 처리에 최적화되어 있습니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 277,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 개론",
    "question_number": 19,
    "question": "[변형] ETL 프로세스에서 'T'가 의미하는 것은?",
    "options": [
      "Transfer",
      "Transform",
      "Transmit",
      "Transpose"
    ],
    "correct": 1,
    "explanation": "ETL은 Extraction(추출), Transformation(변환), Loading(적재)의 약자입니다. 'T'는 Transform(변환)을 의미합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 278,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 20,
    "question": "[변형] 베이즈 정리에서 P(A|B) × P(B) = ?",
    "options": [
      "P(B|A)",
      "P(A∩B)",
      "P(A∪B)",
      "P(A) × P(B)"
    ],
    "correct": 1,
    "explanation": "베이즈 정리: P(A|B) = P(B|A) × P(A) / P(B)에서 P(A|B) × P(B) = P(B|A) × P(A) = P(A∩B)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 279,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 21,
    "question": "[변형] Forward Selection 변수 선택법의 특징은?",
    "options": [
      "모든 변수로 시작하여 제거해 나간다",
      "변수 없이 시작하여 추가해 나간다",
      "전진과 후진을 반복한다",
      "무작위로 변수를 선택한다"
    ],
    "correct": 1,
    "explanation": "Forward Selection은 변수 없이 시작하여 유의한 변수를 하나씩 추가해 나가는 방법입니다. Backward Elimination은 모든 변수로 시작하여 제거해 나갑니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 280,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 22,
    "question": "[변형] 불균형 데이터 처리 방법이 아닌 것은?",
    "options": [
      "Under-sampling",
      "Over-sampling",
      "Weight Balancing",
      "Data Normalization"
    ],
    "correct": 3,
    "explanation": "불균형 데이터 처리 방법에는 Under-sampling(다수 클래스 축소), Over-sampling(소수 클래스 확대), Weight Balancing(가중치 조정) 등이 있습니다. Data Normalization은 스케일링 기법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 281,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 23,
    "question": "[변형] SMOTE 기법에 대한 설명으로 옳은 것은?",
    "options": [
      "Under-sampling 기법이다",
      "Over-sampling 기법이다",
      "정규화 기법이다",
      "차원축소 기법이다"
    ],
    "correct": 1,
    "explanation": "SMOTE(Synthetic Minority Oversampling Technique)는 소수 클래스의 합성 데이터를 생성하여 데이터 불균형을 해결하는 Over-sampling 기법입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 282,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 24,
    "question": "[변형] t-검정에서 사용하는 분포는?",
    "options": [
      "정규분포",
      "t-분포",
      "카이제곱분포",
      "F-분포"
    ],
    "correct": 1,
    "explanation": "t-검정은 모표준편차를 모를 때 사용하며, t-분포를 따릅니다. 표본 크기가 클수록 정규분포에 근사합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 283,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 25,
    "question": "[변형] 다중공선성(Multicollinearity) 진단 지표로 사용되는 것은?",
    "options": [
      "R-squared",
      "VIF",
      "AIC",
      "MSE"
    ],
    "correct": 1,
    "explanation": "VIF(Variance Inflation Factor)는 다중공선성을 진단하는 지표입니다. 일반적으로 VIF > 10이면 심각한 다중공선성이 있다고 판단합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 284,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 26,
    "question": "[변형] 결측값 처리 방법 중 MCAR은 무엇의 약자인가?",
    "options": [
      "Missing Completely At Random",
      "Missing Conditionally At Random",
      "Missing Constantly At Random",
      "Missing Correctly At Random"
    ],
    "correct": 0,
    "explanation": "MCAR은 Missing Completely At Random의 약자로, 결측값이 완전히 무작위로 발생한 경우를 의미합니다. MAR(Missing At Random), MNAR(Missing Not At Random)과 구별됩니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 285,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 27,
    "question": "[변형] 이상값 탐지 방법 중 IQR을 이용한 방법에서 이상값의 기준은?",
    "options": [
      "Q1 - 1.0×IQR 미만, Q3 + 1.0×IQR 초과",
      "Q1 - 1.5×IQR 미만, Q3 + 1.5×IQR 초과",
      "Q1 - 2.0×IQR 미만, Q3 + 2.0×IQR 초과",
      "Q1 - 3.0×IQR 미만, Q3 + 3.0×IQR 초과"
    ],
    "correct": 1,
    "explanation": "IQR(Inter Quartile Range) 방법에서는 Q1 - 1.5×IQR 미만이거나 Q3 + 1.5×IQR 초과하는 값을 이상값으로 판단합니다. IQR = Q3 - Q1입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 286,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 28,
    "question": "[변형] Z-score 정규화 공식에서 분모에 해당하는 것은?",
    "options": [
      "평균",
      "최댓값",
      "표준편차",
      "중앙값"
    ],
    "correct": 2,
    "explanation": "Z-score 정규화는 Z = (X - μ)/σ 공식을 사용합니다. 여기서 μ는 평균, σ는 표준편차입니다. 표준편차가 분모에 해당합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 287,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 29,
    "question": "[변형] Min-Max 정규화의 결과 범위는?",
    "options": [
      "[-1, 1]",
      "[0, 1]",
      "[-∞, ∞]",
      "[0, 100]"
    ],
    "correct": 1,
    "explanation": "Min-Max 정규화는 데이터를 0과 1 사이의 값으로 변환하는 방법입니다. 공식: (X - min)/(max - min)",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 288,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 30,
    "question": "[변형] 원-핫 인코딩(One-Hot Encoding)에 대한 설명으로 옳은 것은?",
    "options": [
      "수치형 데이터를 범주형으로 변환한다",
      "범주형 데이터를 0과 1로 이루어진 벡터로 변환한다",
      "연속형 데이터를 구간별로 나눈다",
      "결측값을 평균으로 대체한다"
    ],
    "correct": 1,
    "explanation": "원-핫 인코딩은 범주형 데이터를 0과 1로 이루어진 벡터로 변환하는 방법입니다. 각 범주마다 새로운 이진 변수를 생성합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 289,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 31,
    "question": "[변형] PCA(주성분 분석)의 목적은?",
    "options": [
      "데이터 양을 증가시킨다",
      "차원을 축소한다",
      "결측값을 처리한다",
      "이상값을 제거한다"
    ],
    "correct": 1,
    "explanation": "PCA(Principal Component Analysis)는 고차원 데이터를 저차원으로 축소하여 차원의 저주를 해결하고 계산 효율성을 높이는 기법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 290,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 32,
    "question": "[변형] 피어슨 상관계수의 범위는?",
    "options": [
      "[0, 1]",
      "[-1, 1]",
      "[0, ∞]",
      "[-∞, ∞]"
    ],
    "correct": 1,
    "explanation": "피어슨 상관계수는 -1과 1 사이의 값을 가집니다. -1에 가까우면 강한 음의 상관관계, 1에 가까우면 강한 양의 상관관계, 0에 가까우면 상관관계가 없음을 의미합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 291,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 33,
    "question": "[변형] 첨도(Kurtosis)가 3보다 클 때 분포의 특징은?",
    "options": [
      "평평한 분포",
      "뾰족한 분포",
      "치우친 분포",
      "정규 분포"
    ],
    "correct": 1,
    "explanation": "첨도가 3보다 크면 뾰족한 분포(leptokurtic), 3보다 작으면 평평한 분포(platykurtic), 3이면 정규분포(mesokurtic)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 292,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 34,
    "question": "[변형] 왜도(Skewness)가 0보다 클 때 분포의 특징은?",
    "options": [
      "좌편향 분포",
      "우편향 분포",
      "정규 분포",
      "이봉 분포"
    ],
    "correct": 1,
    "explanation": "왜도가 0보다 크면 우편향(right-skewed) 분포, 0보다 작으면 좌편향(left-skewed) 분포, 0이면 대칭 분포입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 293,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 35,
    "question": "[변형] 중심극한정리에서 표본 크기가 얼마 이상일 때 정규분포에 근사한다고 보는가?",
    "options": [
      "20",
      "30",
      "50",
      "100"
    ],
    "correct": 1,
    "explanation": "중심극한정리에 의하면 표본 크기가 30 이상일 때 표본평균의 분포가 정규분포에 근사한다고 봅니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 294,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 36,
    "question": "[변형] 표준오차(Standard Error)를 구하는 공식에서 분모는?",
    "options": [
      "표본 크기",
      "표본 크기의 제곱근",
      "표준편차",
      "분산"
    ],
    "correct": 1,
    "explanation": "표준오차 = σ/√n (σ: 모표준편차, n: 표본크기) 또는 s/√n (s: 표본표준편차)입니다. 분모는 표본 크기의 제곱근입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 295,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 37,
    "question": "[변형] 95% 신뢰구간에서 사용하는 Z값은?",
    "options": [
      "1.64",
      "1.96",
      "2.33",
      "2.58"
    ],
    "correct": 1,
    "explanation": "95% 신뢰구간에서는 α=0.05이므로 α/2=0.025입니다. 따라서 Z_{0.025} = 1.96을 사용합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 296,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 기획",
    "question_number": 38,
    "question": "[변형] 가설검정에서 1종 오류(Type I Error)는?",
    "options": [
      "귀무가설이 참인데 귀무가설을 기각하는 오류",
      "귀무가설이 거짓인데 귀무가설을 채택하는 오류",
      "대립가설이 참인데 대립가설을 기각하는 오류",
      "대립가설이 거짓인데 대립가설을 채택하는 오류"
    ],
    "correct": 0,
    "explanation": "1종 오류(Type I Error)는 귀무가설이 참인데 이를 기각하는 오류입니다. 2종 오류(Type II Error)는 귀무가설이 거짓인데 이를 채택하는 오류입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 297,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 39,
    "question": "[변형] ARIMA(p,d,q) 모델에서 'd'가 의미하는 것은?",
    "options": [
      "자기회귀 차수",
      "이동평균 차수",
      "차분 차수",
      "계절성 차수"
    ],
    "correct": 2,
    "explanation": "ARIMA(p,d,q)에서 p는 자기회귀(AR) 차수, d는 차분(Differencing) 차수, q는 이동평균(MA) 차수를 의미합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 298,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 40,
    "question": "[변형] 베이지안 분류에서 나이브(Naive)의 의미는?",
    "options": [
      "단순함",
      "독립성 가정",
      "확률적",
      "조건부"
    ],
    "correct": 1,
    "explanation": "나이브 베이즈에서 '나이브(Naive)'는 모든 특성들이 서로 독립이라고 가정하는 것을 의미합니다. 이는 현실적이지 않은 가정이지만 계산을 단순화합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 299,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 41,
    "question": "[변형] CNN에서 컨볼루션 연산의 목적은?",
    "options": [
      "차원을 축소한다",
      "지역적 특징을 추출한다",
      "과적합을 방지한다",
      "계산량을 줄인다"
    ],
    "correct": 1,
    "explanation": "CNN의 컨볼루션 연산은 필터(커널)를 사용하여 입력 데이터의 지역적 특징(local features)을 추출하는 역할을 합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 300,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 42,
    "question": "[변형] RNN에서 장기 의존성 문제를 해결하는 모델은?",
    "options": [
      "LSTM",
      "CNN",
      "SVM",
      "Decision Tree"
    ],
    "correct": 0,
    "explanation": "LSTM(Long Short-Term Memory)은 RNN의 장기 의존성 문제와 기울기 소실 문제를 해결하기 위해 개발된 모델입니다. GRU도 유사한 목적으로 사용됩니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 301,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 43,
    "question": "[변형] 랜덤 포레스트의 특징으로 옳지 않은 것은?",
    "options": [
      "배깅(Bagging) 기법을 사용한다",
      "여러 의사결정나무를 결합한다",
      "과적합에 강하다",
      "선형 모델이다"
    ],
    "correct": 3,
    "explanation": "랜덤 포레스트는 배깅을 사용한 앙상블 모델로, 여러 의사결정나무를 결합하여 과적합에 강한 특징이 있습니다. 비선형 모델입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 302,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 44,
    "question": "[변형] 부스팅(Boosting) 앙상블의 특징은?",
    "options": [
      "모델을 독립적으로 학습한다",
      "순차적으로 학습하여 오류를 보완한다",
      "모든 모델에 동일한 가중치를 부여한다",
      "배깅과 동일한 방법이다"
    ],
    "correct": 1,
    "explanation": "부스팅은 모델을 순차적으로 학습하면서 이전 모델의 오류를 다음 모델이 보완하도록 하는 앙상블 기법입니다. 대표적으로 AdaBoost, Gradient Boosting이 있습니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 303,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 45,
    "question": "[변형] 회귀분석에서 R-squared가 의미하는 것은?",
    "options": [
      "오차의 제곱합",
      "총변동에 대한 회귀변동의 비율",
      "독립변수의 개수",
      "표본의 크기"
    ],
    "correct": 1,
    "explanation": "R-squared(결정계수)는 총변동에 대한 회귀변동의 비율로, 독립변수가 종속변수의 변동을 얼마나 설명하는지를 나타냅니다. R² = SSR/SST",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 304,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 46,
    "question": "[변형] 로지스틱 회귀에서 사용하는 활성화 함수는?",
    "options": [
      "ReLU",
      "Sigmoid",
      "Tanh",
      "Linear"
    ],
    "correct": 1,
    "explanation": "로지스틱 회귀에서는 Sigmoid 함수를 사용하여 선형 조합을 0과 1 사이의 확률값으로 변환합니다. Sigmoid(z) = 1/(1+e^(-z))",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 305,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 47,
    "question": "[변형] 의사결정나무에서 과적합을 방지하는 방법이 아닌 것은?",
    "options": [
      "가지치기(Pruning)",
      "정지규칙(Stopping Rule)",
      "최대 깊이 제한",
      "학습률 조정"
    ],
    "correct": 3,
    "explanation": "의사결정나무에서 과적합 방지 방법에는 가지치기, 정지규칙, 최대 깊이 제한, 최소 분할 샘플 수 설정 등이 있습니다. 학습률 조정은 신경망에서 사용하는 방법입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 306,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 48,
    "question": "[변형] 신경망에서 ReLU 함수의 특징으로 옳지 않은 것은?",
    "options": [
      "계산이 간단하다",
      "기울기 소실 문제를 완화한다",
      "음수 입력에 대해 0을 출력한다",
      "모든 범위에서 미분 가능하다"
    ],
    "correct": 3,
    "explanation": "ReLU 함수는 x=0에서 미분이 불가능합니다. ReLU(x) = max(0, x)로 정의되며, x < 0일 때 0, x > 0일 때 x를 출력합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 307,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 49,
    "question": "[변형] SVM에서 커널 함수의 역할은?",
    "options": [
      "선형 분리 가능한 데이터만 처리한다",
      "비선형 데이터를 고차원 공간으로 매핑한다",
      "학습 속도를 향상시킨다",
      "메모리 사용량을 줄인다"
    ],
    "correct": 1,
    "explanation": "SVM의 커널 함수는 비선형 데이터를 고차원 특성 공간으로 매핑하여 선형 분리 가능하게 만드는 역할을 합니다. 대표적으로 RBF, 다항식, 시그모이드 커널이 있습니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 308,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 50,
    "question": "[변형] 연관규칙에서 지지도(Support)의 정의는?",
    "options": [
      "P(A∩B)/P(A)",
      "P(A∩B)",
      "P(A∩B)/P(B)",
      "P(A)×P(B)"
    ],
    "correct": 1,
    "explanation": "지지도(Support)는 P(A∩B)로 정의됩니다. 신뢰도(Confidence)는 P(B|A) = P(A∩B)/P(A), 향상도(Lift)는 P(B|A)/P(B)입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 309,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 51,
    "question": "[변형] K-Means 클러스터링에서 K를 결정하는 방법으로 적절한 것은?",
    "options": [
      "실루엣 분석",
      "엘보우 방법",
      "WCSS 분석",
      "모두 맞다"
    ],
    "correct": 3,
    "explanation": "K-Means에서 최적의 K를 결정하는 방법에는 엘보우 방법(Elbow Method), 실루엣 분석(Silhouette Analysis), WCSS 분석 등이 모두 사용됩니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 310,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 52,
    "question": "[변형] DBSCAN 클러스터링의 매개변수가 아닌 것은?",
    "options": [
      "eps (반경)",
      "min_samples (최소 점의 수)",
      "k (클러스터 수)",
      "metric (거리 측정법)"
    ],
    "correct": 2,
    "explanation": "DBSCAN의 주요 매개변수는 eps(이웃을 정의하는 반경), min_samples(핵심점이 되기 위한 최소 이웃 수)입니다. K-Means와 달리 클러스터 수를 미리 정하지 않습니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 311,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 53,
    "question": "[변형] 시계열 분석에서 정상성(Stationarity)의 조건이 아닌 것은?",
    "options": [
      "평균이 시간에 무관하게 일정하다",
      "분산이 시간에 무관하게 일정하다",
      "자기공분산이 시차에만 의존한다",
      "추세가 지속적으로 증가한다"
    ],
    "correct": 3,
    "explanation": "정상성(Stationarity)의 조건은 ①평균이 시간에 무관하게 일정 ②분산이 시간에 무관하게 일정 ③자기공분산이 시차에만 의존입니다. 추세가 있으면 비정상 시계열입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 312,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 54,
    "question": "[변형] ARIMA(p,d,q) 모델에서 'd'가 의미하는 것은?",
    "options": [
      "자기회귀 차수",
      "이동평균 차수",
      "차분 차수",
      "계절성 차수"
    ],
    "correct": 2,
    "explanation": "ARIMA(p,d,q)에서 p는 자기회귀(AR) 차수, d는 차분(Differencing) 차수, q는 이동평균(MA) 차수를 의미합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 313,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 55,
    "question": "[변형] 베이지안 분류에서 나이브(Naive)의 의미는?",
    "options": [
      "단순함",
      "독립성 가정",
      "확률적",
      "조건부"
    ],
    "correct": 1,
    "explanation": "나이브 베이즈에서 '나이브(Naive)'는 모든 특성들이 서로 독립이라고 가정하는 것을 의미합니다. 이는 현실적이지 않은 가정이지만 계산을 단순화합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 314,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 56,
    "question": "[변형] CNN에서 컨볼루션 연산의 목적은?",
    "options": [
      "차원을 축소한다",
      "지역적 특징을 추출한다",
      "과적합을 방지한다",
      "계산량을 줄인다"
    ],
    "correct": 1,
    "explanation": "CNN의 컨볼루션 연산은 필터(커널)를 사용하여 입력 데이터의 지역적 특징(local features)을 추출하는 역할을 합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 315,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 모델링",
    "question_number": 57,
    "question": "[변형] RNN에서 장기 의존성 문제를 해결하는 모델은?",
    "options": [
      "LSTM",
      "CNN",
      "SVM",
      "Decision Tree"
    ],
    "correct": 0,
    "explanation": "LSTM(Long Short-Term Memory)은 RNN의 장기 의존성 문제와 기울기 소실 문제를 해결하기 위해 개발된 모델입니다. GRU도 유사한 목적으로 사용됩니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 316,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 결과해석",
    "question_number": 58,
    "question": "[변형] 시각화에서 산점도(Scatter Plot)가 가장 적합한 용도는?",
    "options": [
      "범주별 빈도 비교",
      "두 연속형 변수의 상관관계",
      "시간에 따른 변화",
      "분포의 형태"
    ],
    "correct": 1,
    "explanation": "산점도는 두 연속형 변수 간의 상관관계나 패턴을 시각화하는 데 가장 적합합니다. 막대그래프는 범주별 비교, 선그래프는 시간 변화, 히스토그램은 분포 형태에 적합합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 317,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 결과해석",
    "question_number": 59,
    "question": "[변형] Confusion Matrix에서 Type I Error는?",
    "options": [
      "True Positive",
      "True Negative",
      "False Positive",
      "False Negative"
    ],
    "correct": 2,
    "explanation": "Type I Error는 False Positive(FP)로, 실제로는 음성인데 양성으로 잘못 분류한 경우입니다. Type II Error는 False Negative(FN)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 318,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 결과해석",
    "question_number": 60,
    "question": "[변형] Bootstrap 샘플링에서 Out-of-Bag 비율은 약 얼마인가?",
    "options": [
      "36.8%",
      "50%",
      "63.2%",
      "70%"
    ],
    "correct": 0,
    "explanation": "Bootstrap 샘플링에서 복원추출로 인해 선택되지 않을 확률은 약 36.8%입니다. 이를 Out-of-Bag(OOB) 샘플이라고 합니다.",
    "difficulty": "★★★★★",
    "difficulty_level": 5
  },
  {
    "id": 319,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 결과해석",
    "question_number": 61,
    "question": "[변형] L2 정규화(Ridge)에서 람다(λ) 값이 클수록?",
    "options": [
      "과적합이 증가한다",
      "모델 복잡도가 증가한다",
      "가중치 감소 효과가 커진다",
      "정확도가 항상 향상된다"
    ],
    "correct": 2,
    "explanation": "L2 정규화에서 λ 값이 클수록 가중치를 더 많이 감소시켜 모델을 단순하게 만들고 과적합을 방지합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 320,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 결과해석",
    "question_number": 62,
    "question": "[변형] Adjusted R-squared가 R-squared보다 낮은 이유는?",
    "options": [
      "계산 오류",
      "독립변수 개수에 대한 페널티",
      "종속변수의 영향",
      "표본 크기의 영향"
    ],
    "correct": 1,
    "explanation": "Adjusted R-squared는 독립변수의 개수가 증가할 때 발생하는 R-squared의 과대추정을 보정하기 위해 독립변수 개수에 대한 페널티를 부과합니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 321,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 결과해석",
    "question_number": 63,
    "question": "[변형] 엘보우 방법(Elbow Method)이 사용되는 목적은?",
    "options": [
      "최적의 학습률 찾기",
      "최적의 클러스터 수 결정",
      "특성 선택",
      "모델 성능 평가"
    ],
    "correct": 1,
    "explanation": "엘보우 방법은 K-Means 클러스터링에서 최적의 클러스터 수(K)를 결정하기 위해 WCSS(Within-Cluster Sum of Squares)의 변화를 관찰하는 방법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 322,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 결과해석",
    "question_number": 64,
    "question": "[변형] 혼동행렬에서 Precision(정밀도)을 구하는 공식은?",
    "options": [
      "TP / (TP + FN)",
      "TP / (TP + FP)",
      "TN / (TN + FP)",
      "TN / (TN + FN)"
    ],
    "correct": 1,
    "explanation": "정밀도(Precision) = TP / (TP + FP)입니다. 예측한 양성 중에서 실제 양성인 비율을 의미합니다. 재현율(Recall) = TP / (TP + FN)입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 323,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 결과해석",
    "question_number": 65,
    "question": "[변형] F1-score는 다음 중 어떤 두 지표의 조화평균인가?",
    "options": [
      "Accuracy와 Precision",
      "Precision과 Recall",
      "Recall과 Specificity",
      "Accuracy와 Recall"
    ],
    "correct": 1,
    "explanation": "F1-score는 정밀도(Precision)와 재현율(Recall)의 조화평균입니다. F1 = 2 × (Precision × Recall) / (Precision + Recall)",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 324,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 결과해석",
    "question_number": 66,
    "question": "[변형] ROC 곡선의 x축과 y축은?",
    "options": [
      "FPR, TPR",
      "TPR, FPR",
      "Precision, Recall",
      "Accuracy, F1-score"
    ],
    "correct": 0,
    "explanation": "ROC 곡선의 x축은 FPR(False Positive Rate), y축은 TPR(True Positive Rate)입니다. FPR = FP/(FP+TN), TPR = TP/(TP+FN)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 325,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 결과해석",
    "question_number": 67,
    "question": "[변형] AUC 값이 0.5에 가까울 때의 의미는?",
    "options": [
      "완벽한 분류기",
      "매우 좋은 분류기",
      "무작위 분류기 수준",
      "최악의 분류기"
    ],
    "correct": 2,
    "explanation": "AUC(Area Under the Curve) 값이 0.5는 무작위 분류기 수준을 의미합니다. 1에 가까울수록 좋은 분류기, 0.8~0.9면 우수한 분류기로 평가합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 326,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 결과해석",
    "question_number": 68,
    "question": "[변형] 회귀 모델의 평가지표 중 RMSE는 무엇의 약자인가?",
    "options": [
      "Root Mean Square Error",
      "Relative Mean Square Error",
      "Random Mean Square Error",
      "Robust Mean Square Error"
    ],
    "correct": 0,
    "explanation": "RMSE는 Root Mean Square Error(평균제곱근오차)의 약자입니다. MSE에 제곱근을 취한 값으로, 실제값과 예측값의 차이를 나타냅니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 327,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 결과해석",
    "question_number": 69,
    "question": "[변형] 실루엣 계수(Silhouette Coefficient)의 범위는?",
    "options": [
      "[0, 1]",
      "[-1, 1]",
      "[0, ∞]",
      "[-∞, ∞]"
    ],
    "correct": 1,
    "explanation": "실루엣 계수는 -1과 1 사이의 값을 가집니다. 1에 가까우면 잘 분류됨, 0에 가까우면 경계에 있음, -1에 가까우면 잘못 분류됨을 의미합니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 328,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 결과해석",
    "question_number": 70,
    "question": "[변형] K-Fold 교차검증에서 K=5일 때 훈련 데이터의 비율은?",
    "options": [
      "20%",
      "40%",
      "60%",
      "80%"
    ],
    "correct": 3,
    "explanation": "K-Fold 교차검증에서 K=5이면 데이터를 5등분하여 1개를 검증용(20%), 4개를 훈련용(80%)으로 사용합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 329,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 결과해석",
    "question_number": 71,
    "question": "[변형] 과적합(Overfitting)을 방지하는 방법이 아닌 것은?",
    "options": [
      "Dropout",
      "L2 Regularization",
      "더 복잡한 모델 사용",
      "Early Stopping"
    ],
    "correct": 2,
    "explanation": "과적합 방지 방법에는 Dropout, 정규화(L1/L2), Early Stopping, 데이터 증강 등이 있습니다. 더 복잡한 모델을 사용하면 과적합이 더 심해집니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 330,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 결과해석",
    "question_number": 72,
    "question": "[변형] GridSearchCV의 목적은?",
    "options": [
      "과적합을 방지한다",
      "하이퍼파라미터를 최적화한다",
      "특성을 선택한다",
      "데이터를 전처리한다"
    ],
    "correct": 1,
    "explanation": "GridSearchCV는 하이퍼파라미터의 최적 조합을 찾기 위해 격자 탐색(Grid Search)과 교차검증을 결합한 방법입니다.",
    "difficulty": "★★★",
    "difficulty_level": 3
  },
  {
    "id": 331,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 결과해석",
    "question_number": 73,
    "question": "[변형] 시각화에서 산점도(Scatter Plot)가 가장 적합한 용도는?",
    "options": [
      "범주별 빈도 비교",
      "두 연속형 변수의 상관관계",
      "시간에 따른 변화",
      "분포의 형태"
    ],
    "correct": 1,
    "explanation": "산점도는 두 연속형 변수 간의 상관관계나 패턴을 시각화하는 데 가장 적합합니다. 막대그래프는 범주별 비교, 선그래프는 시간 변화, 히스토그램은 분포 형태에 적합합니다.",
    "difficulty": "★★",
    "difficulty_level": 2
  },
  {
    "id": 332,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 결과해석",
    "question_number": 74,
    "question": "[변형] Confusion Matrix에서 Type I Error는?",
    "options": [
      "True Positive",
      "True Negative",
      "False Positive",
      "False Negative"
    ],
    "correct": 2,
    "explanation": "Type I Error는 False Positive(FP)로, 실제로는 음성인데 양성으로 잘못 분류한 경우입니다. Type II Error는 False Negative(FN)입니다.",
    "difficulty": "★★★★",
    "difficulty_level": 4
  },
  {
    "id": 333,
    "type": "예상문제",
    "round": "4회차",
    "section": "빅데이터 결과해석",
    "question_number": 75,
    "question": "[변형] Bootstrap 샘플링에서 Out-of-Bag 비율은 약 얼마인가?",
    "options": [
      "36.8%",
      "50%",
      "63.2%",
      "70%"
    ],
    "correct": 0,
    "explanation": "Bootstrap 샘플링에서 복원추출로 인해 선택되지 않을 확률은 약 36.8%입니다. 이를 Out-of-Bag(OOB) 샘플이라고 합니다.",
    "difficulty": "★★★★★",
    "difficulty_level": 5
  }
]